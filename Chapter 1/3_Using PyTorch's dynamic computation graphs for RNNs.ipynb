{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_Using PyTorch's dynamic computation graphs for RNNs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "hf6P0mwYVayb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Importing PyTorch into the environment**"
      ]
    },
    {
      "metadata": {
        "id": "JIY7QJba6RLj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IEMcSvHKVfbR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Using higher - level abstraction. First, we need to set the size of our random training data.**"
      ]
    },
    {
      "metadata": {
        "id": "ZArIwktcRTuv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "input_shape = 5\n",
        "output_shape = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kua6MFaMVpOE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**To make use of GPUs, cast the tensors as follows.**\n",
        "**This ensures that all computations will use the attached GPU**"
      ]
    },
    {
      "metadata": {
        "id": "V3OjBFUTR8ld",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.set_default_tensor_type('torch.cuda.FloatTensor')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "at-TiU8cV9Y0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Generating random training data:**"
      ]
    },
    {
      "metadata": {
        "id": "BGEFkThtSDoJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "X = Variable(torch.randn(batch_size, input_shape))\n",
        "y = Variable(torch.randn(batch_size, output_shape), \n",
        "             requires_grad = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TNML_uWRWG_v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Using a simple neural network having 1 hidden layer with 32 units and an output layer. We use the .cuda() extension to make sure the model runs on the GPU**"
      ]
    },
    {
      "metadata": {
        "id": "ylDT0vD4Sq-6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = torch.nn.Sequential(\n",
        "  torch.nn.Linear(input_shape, 32),\n",
        "  torch.nn.Linear(32, output_shape),\n",
        "  ).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Eg7LQY_sX9dP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Defining the MSE loss function**"
      ]
    },
    {
      "metadata": {
        "id": "wfhUJEYBS8sC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss_function = torch.nn.MSELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o1EAe5k4YCAu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Training the model for 10 epochs:**"
      ]
    },
    {
      "metadata": {
        "id": "zzrLq_OATFXp",
        "colab_type": "code",
        "outputId": "c96290c6-2e3c-47a7-f3db-8296629106f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "\n",
        "for i in range(10):\n",
        "  y_pred = model(X)\n",
        "  loss = loss_function(y_pred, y)\n",
        "  print(loss)\n",
        "  #print(loss.data[0])\n",
        "  \n",
        "  # Zero gradients\n",
        "  model.zero_grad()\n",
        "  loss.backward()\n",
        "  \n",
        "  # Update weights\n",
        "  for param in model.parameters():\n",
        "    param.data -= learning_rate * param.grad.data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.2381, grad_fn=<MseLossBackward>)\n",
            "tensor(1.2376, grad_fn=<MseLossBackward>)\n",
            "tensor(1.2371, grad_fn=<MseLossBackward>)\n",
            "tensor(1.2366, grad_fn=<MseLossBackward>)\n",
            "tensor(1.2360, grad_fn=<MseLossBackward>)\n",
            "tensor(1.2355, grad_fn=<MseLossBackward>)\n",
            "tensor(1.2350, grad_fn=<MseLossBackward>)\n",
            "tensor(1.2345, grad_fn=<MseLossBackward>)\n",
            "tensor(1.2339, grad_fn=<MseLossBackward>)\n",
            "tensor(1.2334, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}