{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7_Applying a 1D CNN to text.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "cxqaUdiiWlN-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Let's start with importing the libraries as follows:**"
      ]
    },
    {
      "metadata": {
        "id": "4a_ozNsqHnda",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4b19dbbc-e5f5-413f-9d07-987a6b533b5d"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.datasets import imdb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "IPhw6x81Wr7U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**We will be using the imdb dataset from keras; load the data with the following code:**"
      ]
    },
    {
      "metadata": {
        "id": "WVAet1qGKSfK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "680e1ff5-0d04-40cb-89d5-d070d3a5b594"
      },
      "cell_type": "code",
      "source": [
        "n_words = 1000\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = n_words)\n",
        "print('Train seq: {}'.format(len(X_train)))\n",
        "print('Test seq: {}'.format(len(X_test)))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n",
            "Train seq: 25000\n",
            "Test seq: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jW8TpBGAXAXB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Let's print an example output of the training and test data:**"
      ]
    },
    {
      "metadata": {
        "id": "8F3oH9GEK5j5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "b34ea16d-745d-4996-9431-ea4d008e66a3"
      },
      "cell_type": "code",
      "source": [
        "print('Train example: \\n{}'.format(X_train[0]))\n",
        "print('\\nTest example: \\n{}'.format(X_test[0]))\n",
        "\n",
        "# Note: the data is already preprocessed (words are mapped to vectors)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train example: \n",
            "[1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n",
            "\n",
            "Test example: \n",
            "[1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 2, 394, 354, 4, 123, 9, 2, 2, 2, 10, 10, 13, 92, 124, 89, 488, 2, 100, 28, 2, 14, 31, 23, 27, 2, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 2, 451, 202, 14, 6, 717]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "blWE1oSvXQRd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**By padding the sequences, we prepare our input for our network:**"
      ]
    },
    {
      "metadata": {
        "id": "HDYAuX_WMbFd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Pad sequences with max_len\n",
        "\n",
        "max_len = 200\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train, maxlen = max_len)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen = max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "deYCR8V6XlJs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**We are now ready to define our network architecture:**"
      ]
    },
    {
      "metadata": {
        "id": "9SghDKNrOLAv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "outputId": "aeb20f28-028a-4b4c-ec1c-b5a7e6362670"
      },
      "cell_type": "code",
      "source": [
        "# Define network architecture and compile\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(n_words, 50, input_length = max_len))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv1D(128, 3, padding = 'valid', \n",
        "                 activation = 'relu', strides = 1,))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(250, activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy',\n",
        "              optimizer = 'adam',\n",
        "              metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 200, 50)           50000     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 200, 50)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 198, 128)          19328     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 250)               32250     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 251       \n",
            "=================================================================\n",
            "Total params: 101,829\n",
            "Trainable params: 101,829\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vdXMBmxtXsNL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**We define a callback function to prevent overfitting on the training data:**"
      ]
    },
    {
      "metadata": {
        "id": "wICJNCrDQJ6b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "callbacks = [EarlyStopping(monitor = 'val_acc', patience = 3)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s6-heui8YS2U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Let's define the hyperparameters and start training our network:**"
      ]
    },
    {
      "metadata": {
        "id": "TjZe5ydYQhmQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "outputId": "8725c964-36e4-4460-f599-ef1420063c31"
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 100\n",
        "batch_size = 64\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size = batch_size,\n",
        "          epochs = n_epochs,\n",
        "          validation_split = 0.2,\n",
        "          callbacks = callbacks)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/100\n",
            "20000/20000 [==============================] - 8s 411us/step - loss: 0.5827 - acc: 0.6628 - val_loss: 0.4080 - val_acc: 0.8202\n",
            "Epoch 2/100\n",
            "20000/20000 [==============================] - 3s 128us/step - loss: 0.3965 - acc: 0.8254 - val_loss: 0.3683 - val_acc: 0.8388\n",
            "Epoch 3/100\n",
            "20000/20000 [==============================] - 3s 128us/step - loss: 0.3516 - acc: 0.8448 - val_loss: 0.3320 - val_acc: 0.8528\n",
            "Epoch 4/100\n",
            "20000/20000 [==============================] - 3s 128us/step - loss: 0.3294 - acc: 0.8571 - val_loss: 0.3393 - val_acc: 0.8498\n",
            "Epoch 5/100\n",
            "20000/20000 [==============================] - 3s 127us/step - loss: 0.3136 - acc: 0.8678 - val_loss: 0.3228 - val_acc: 0.8568\n",
            "Epoch 6/100\n",
            "20000/20000 [==============================] - 3s 128us/step - loss: 0.3037 - acc: 0.8710 - val_loss: 0.3116 - val_acc: 0.8592\n",
            "Epoch 7/100\n",
            "20000/20000 [==============================] - 3s 128us/step - loss: 0.2920 - acc: 0.8789 - val_loss: 0.3126 - val_acc: 0.8622\n",
            "Epoch 8/100\n",
            "20000/20000 [==============================] - 3s 128us/step - loss: 0.2839 - acc: 0.8821 - val_loss: 0.3086 - val_acc: 0.8644\n",
            "Epoch 9/100\n",
            "20000/20000 [==============================] - 3s 128us/step - loss: 0.2749 - acc: 0.8855 - val_loss: 0.3234 - val_acc: 0.8570\n",
            "Epoch 10/100\n",
            "20000/20000 [==============================] - 3s 127us/step - loss: 0.2694 - acc: 0.8898 - val_loss: 0.3050 - val_acc: 0.8708\n",
            "Epoch 11/100\n",
            "20000/20000 [==============================] - 3s 127us/step - loss: 0.2583 - acc: 0.8961 - val_loss: 0.3128 - val_acc: 0.8632\n",
            "Epoch 12/100\n",
            "20000/20000 [==============================] - 3s 127us/step - loss: 0.2541 - acc: 0.8962 - val_loss: 0.3384 - val_acc: 0.8522\n",
            "Epoch 13/100\n",
            "20000/20000 [==============================] - 3s 128us/step - loss: 0.2499 - acc: 0.8981 - val_loss: 0.3130 - val_acc: 0.8672\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f05dd7b8588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "JXx_O9bzYaix",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Finally, we can check the performance of our trained network on the test set:**"
      ]
    },
    {
      "metadata": {
        "id": "fuTDhLQqRD4_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8b30e980-b902-45a3-d583-9280c3c67ec8"
      },
      "cell_type": "code",
      "source": [
        "print('\\nAccuracy on test set: {}'.format(model.evaluate(X_test, y_test)[1]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 1s 57us/step\n",
            "\n",
            "Accuracy on test set: 0.87044\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}