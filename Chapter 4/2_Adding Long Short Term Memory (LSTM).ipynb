{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_Adding Long Short - Term Memory (LSTM).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "5GbYYzcYCpJD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Let's start with importing the libraries as follows:**"
      ]
    },
    {
      "metadata": {
        "id": "woeaItRw0p60",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aa234666-75c7-46af-a75f-02774f20042f"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.preprocessing import sequence\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.datasets import imdb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "I9X9lB0VCyWD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**We will be using the IMDB dataset from Keras; load the data with the following code:**"
      ]
    },
    {
      "metadata": {
        "id": "5BmAhH8Z4Iha",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "be6d6403-ebb8-4368-b0b3-3830bdc263a8"
      },
      "cell_type": "code",
      "source": [
        "n_words = 1000\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = n_words)\n",
        "print('Train seq: {}'.format(len(X_train)))\n",
        "print('Test seq: {}'.format(len(X_test)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train seq: 25000\n",
            "Test seq: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6yn3nme9C9HI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Let's print an example output of the training and test data:**"
      ]
    },
    {
      "metadata": {
        "id": "l6-CvR9M5FES",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "fd37aacc-6f3d-4861-9ed8-d4dcff895627"
      },
      "cell_type": "code",
      "source": [
        "print('Train example: \\n{}'.format(X_train[0]))\n",
        "print('\\nTest example: \\n{}'.format(X_test[0]))\n",
        "\n",
        "# Note: the data is already preprocessed (words are mapped to vectors)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train example: \n",
            "[1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n",
            "\n",
            "Test example: \n",
            "[1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 2, 394, 354, 4, 123, 9, 2, 2, 2, 10, 10, 13, 92, 124, 89, 488, 2, 100, 28, 2, 14, 31, 23, 27, 2, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 2, 451, 202, 14, 6, 717]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hXJO5QY6DMxZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**By padding the sequences, we prepare our input for our network:**"
      ]
    },
    {
      "metadata": {
        "id": "rH9Q8tEz5_jM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Pad sequences with max_len\n",
        "\n",
        "max_len = 200\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train, maxlen = max_len)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen = max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B17TL-2wDflV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**We are now ready to define our network architecture:**"
      ]
    },
    {
      "metadata": {
        "id": "nfpLD2Ku6rir",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "98f436e5-046a-4a76-d4f6-c03133556871"
      },
      "cell_type": "code",
      "source": [
        "# Define network architecture and compile\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(n_words, 50, input_length = max_len))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100, dropout = 0.2, recurrent_dropout = 0.2))\n",
        "model.add(Dense(250, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy',\n",
        "              optimizer = 'adam',\n",
        "              metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 200, 50)           50000     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 200, 50)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               60400     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 250)               25250     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 251       \n",
            "=================================================================\n",
            "Total params: 135,901\n",
            "Trainable params: 135,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v366u0dADnpy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Defining the callback function:**"
      ]
    },
    {
      "metadata": {
        "id": "K0KQq_AL8ZcT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "callbacks = [EarlyStopping(monitor = 'val_acc', patience = 3)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I7VPFPd-D2qJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Let's define the hyperparameters and start training our network:**"
      ]
    },
    {
      "metadata": {
        "id": "7mrAENus8r3i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "0210c6c6-6d8d-491f-ca3f-65acee4b2401"
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 100\n",
        "batch_size = 128\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size = batch_size,\n",
        "          epochs = n_epochs,\n",
        "          validation_split = 0.2,\n",
        "          callbacks = callbacks)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/100\n",
            "20000/20000 [==============================] - 81s 4ms/step - loss: 0.5589 - acc: 0.7013 - val_loss: 0.4433 - val_acc: 0.7922\n",
            "Epoch 2/100\n",
            "20000/20000 [==============================] - 79s 4ms/step - loss: 0.4556 - acc: 0.7932 - val_loss: 0.4623 - val_acc: 0.7942\n",
            "Epoch 3/100\n",
            "20000/20000 [==============================] - 79s 4ms/step - loss: 0.4238 - acc: 0.8139 - val_loss: 0.3917 - val_acc: 0.8322\n",
            "Epoch 4/100\n",
            "20000/20000 [==============================] - 78s 4ms/step - loss: 0.4199 - acc: 0.8161 - val_loss: 0.3966 - val_acc: 0.8270\n",
            "Epoch 5/100\n",
            "20000/20000 [==============================] - 78s 4ms/step - loss: 0.4009 - acc: 0.8257 - val_loss: 0.4099 - val_acc: 0.8132\n",
            "Epoch 6/100\n",
            "20000/20000 [==============================] - 78s 4ms/step - loss: 0.3865 - acc: 0.8345 - val_loss: 0.3833 - val_acc: 0.8302\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f17ac706320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "3jnd88VAEQCg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Finally, we can check the performance of our trained network on the test set:**"
      ]
    },
    {
      "metadata": {
        "id": "RSwwXACZ9TL2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "eb62dc2c-4de3-4436-b746-10e2b606e43c"
      },
      "cell_type": "code",
      "source": [
        "print('Accuracy on test set: {}'.format(model.evaluate(X_test, y_test)[1]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 130s 5ms/step\n",
            "Accuracy on test set: 0.83236\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}