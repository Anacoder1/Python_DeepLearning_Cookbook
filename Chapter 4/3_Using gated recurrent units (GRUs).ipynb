{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_Using gated recurrent units (GRUs).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Bczx2VZ5pa2u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Let's start with importing the libraries as follows:**"
      ]
    },
    {
      "metadata": {
        "id": "UX6LnohSFUQO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5f9c5930-9ae7-43eb-d7a7-5bbbfc27e168"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import GRU\n",
        "from keras.preprocessing import sequence\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.datasets import imdb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nIL1mQMNph8b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**We'll be using the IMDB dataset that classifies the sentiment of text; load the data with the following code:**"
      ]
    },
    {
      "metadata": {
        "id": "7d2ZDXfCf75l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "17b8e787-c2f1-462e-ac52-c33b6fede6aa"
      },
      "cell_type": "code",
      "source": [
        "n_words = 1000\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = n_words)\n",
        "print('Train seq: {}'.format(len(X_train)))\n",
        "print('Test seq: {}'.format(len(X_test)))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n",
            "Train seq: 25000\n",
            "Test seq: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_GXW2MeUqG3R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**By padding the sequences, we prepare our input for our network:**"
      ]
    },
    {
      "metadata": {
        "id": "9ZVv-I0egdqP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Pad sequences with max_len\n",
        "\n",
        "max_len = 200\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train, maxlen = max_len)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen = max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PUTz7IbOq659",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**We are now ready to define our network architecture:**"
      ]
    },
    {
      "metadata": {
        "id": "JDGKhlEXhp4m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "0d3b28c5-8da1-49bc-9629-4847e11d2c8f"
      },
      "cell_type": "code",
      "source": [
        "# Define network architecture and compile\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(n_words, 50, input_length = max_len))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(GRU(100, dropout = 0.2, recurrent_dropout = 0.2))\n",
        "model.add(Dense(250, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy',\n",
        "              optimizer = 'adam',\n",
        "              metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 200, 50)           50000     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 200, 50)           0         \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 100)               45300     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 250)               25250     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 251       \n",
            "=================================================================\n",
            "Total params: 120,801\n",
            "Trainable params: 120,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XKBra8ozrrxG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**We use early stopping to prevent overfitting:**"
      ]
    },
    {
      "metadata": {
        "id": "vntXL5ndjOLy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "callbacks = [EarlyStopping(monitor = 'val_acc', patience = 3)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VB3x5vIBr3ja",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Let's define the hyperparameters and start training our network:**"
      ]
    },
    {
      "metadata": {
        "id": "kzE29LV_kEWh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "92de519b-0e74-41df-acb3-3693689ec8e7"
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 100\n",
        "batch_size = 512\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size = batch_size,\n",
        "          epochs = n_epochs,\n",
        "          validation_split = 0.2,\n",
        "          callbacks = callbacks)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/100\n",
            "20000/20000 [==============================] - 20s 1ms/step - loss: 0.6725 - acc: 0.5714 - val_loss: 0.5736 - val_acc: 0.7014\n",
            "Epoch 2/100\n",
            "20000/20000 [==============================] - 17s 849us/step - loss: 0.5307 - acc: 0.7349 - val_loss: 0.4619 - val_acc: 0.7750\n",
            "Epoch 3/100\n",
            "20000/20000 [==============================] - 17s 849us/step - loss: 0.4999 - acc: 0.7610 - val_loss: 0.4965 - val_acc: 0.7532\n",
            "Epoch 4/100\n",
            "20000/20000 [==============================] - 17s 848us/step - loss: 0.4596 - acc: 0.7885 - val_loss: 0.4862 - val_acc: 0.7612\n",
            "Epoch 5/100\n",
            "20000/20000 [==============================] - 17s 851us/step - loss: 0.4468 - acc: 0.7982 - val_loss: 0.4803 - val_acc: 0.7700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f844a6cc898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "97ijvzcjsG9n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Finally, we can check the performance of our trained network on the test set:**"
      ]
    },
    {
      "metadata": {
        "id": "RhrTML28lb9G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "9637a950-d423-45b5-e484-6df32f0a4b02"
      },
      "cell_type": "code",
      "source": [
        "print('Accuracy on test set: {}'.format(model.evaluate(X_test, y_test)[1]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 116s 5ms/step\n",
            "Accuracy on test set: 0.77688\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}