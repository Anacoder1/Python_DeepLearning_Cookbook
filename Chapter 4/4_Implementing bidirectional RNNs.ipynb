{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_Implementing bidirectional RNNs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "_Se31Fcxq0-k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Let's start with importing the libraries as follows:**"
      ]
    },
    {
      "metadata": {
        "id": "TUnfOBcdtKJS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "62950a4d-f05a-4a82-bd00-a9b1dc069bb8"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding, LSTM, Bidirectional\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing import sequence\n",
        "from keras.datasets import imdb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "5fjdQah2q5v4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**We'll be using the IMDB dataset from Keras; load the data with the following code:**"
      ]
    },
    {
      "metadata": {
        "id": "05HTl8G0gfBh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "198a4bab-0928-4453-ee95-3d78dd1184f7"
      },
      "cell_type": "code",
      "source": [
        "n_words = 1000\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = n_words)\n",
        "print('Train seq: {}'.format(len(X_train)))\n",
        "print('Test seq: {}'.format(len(X_test)))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 3s 0us/step\n",
            "Train seq: 25000\n",
            "Test seq: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v5TGRWtWrFjW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Let's print an example output of the training and test data:**"
      ]
    },
    {
      "metadata": {
        "id": "Srp0Jd-pg5Bk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "871ff75c-be43-4dfe-861e-801098efec3f"
      },
      "cell_type": "code",
      "source": [
        "print('Train example: \\n{}'.format(X_train[0]))\n",
        "print('\\nTest example: \\n{}'.format(X_test[0]))\n",
        "\n",
        "# Note: the data is already preprocessed (words are mapped to vectors)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train example: \n",
            "[1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n",
            "\n",
            "Test example: \n",
            "[1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 2, 394, 354, 4, 123, 9, 2, 2, 2, 10, 10, 13, 92, 124, 89, 488, 2, 100, 28, 2, 14, 31, 23, 27, 2, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 2, 451, 202, 14, 6, 717]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "50k_UqolrM9k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**By padding the sequences, we prepare our input for our network:**"
      ]
    },
    {
      "metadata": {
        "id": "6JbP0xSZhVIZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Pad sequences with max_len\n",
        "\n",
        "max_len = 200\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train, maxlen = max_len)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen = max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jTMZxnR2rVrw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**We are now ready to define our network architecture:**"
      ]
    },
    {
      "metadata": {
        "id": "1Knd-cU1iedM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "baaf1491-ed76-4a7f-9677-cf4ce8b46e9b"
      },
      "cell_type": "code",
      "source": [
        "# Define network architecture and compile\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(n_words, 50, input_length = max_len))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(100, dropout = 0.2,\n",
        "                             recurrent_dropout = 0.2)))\n",
        "model.add(Dense(250, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy',\n",
        "              optimizer = 'adam',\n",
        "              metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 200, 50)           50000     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 200, 50)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 200)               120800    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 250)               50250     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 251       \n",
            "=================================================================\n",
            "Total params: 221,301\n",
            "Trainable params: 221,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K5iNO76krfTp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**To prevent overfitting, we will be using early stopping:**"
      ]
    },
    {
      "metadata": {
        "id": "Vh4Bif6kjwnz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "callbacks = [EarlyStopping(monitor = 'val_acc', patience = 3)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0lcLEXm1rvHa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Let's define the hyperparameters and start training our network:**"
      ]
    },
    {
      "metadata": {
        "id": "r6YAHTzmkFpO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 841
        },
        "outputId": "69afdde7-3164-4fa6-d631-a711ebda40fa"
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 100\n",
        "batch_size = 1024\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size = batch_size,\n",
        "          epochs = n_epochs,\n",
        "          validation_split = 0.2,\n",
        "          callbacks = callbacks)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/100\n",
            "20000/20000 [==============================] - 29s 1ms/step - loss: 0.6902 - acc: 0.5305 - val_loss: 0.6717 - val_acc: 0.6598\n",
            "Epoch 2/100\n",
            "20000/20000 [==============================] - 25s 1ms/step - loss: 0.5919 - acc: 0.7100 - val_loss: 0.5062 - val_acc: 0.7538\n",
            "Epoch 3/100\n",
            "20000/20000 [==============================] - 25s 1ms/step - loss: 0.4715 - acc: 0.7804 - val_loss: 0.4524 - val_acc: 0.7874\n",
            "Epoch 4/100\n",
            "20000/20000 [==============================] - 25s 1ms/step - loss: 0.4295 - acc: 0.8077 - val_loss: 0.4395 - val_acc: 0.7954\n",
            "Epoch 5/100\n",
            "20000/20000 [==============================] - 25s 1ms/step - loss: 0.4117 - acc: 0.8205 - val_loss: 0.4349 - val_acc: 0.7992\n",
            "Epoch 6/100\n",
            "20000/20000 [==============================] - 25s 1ms/step - loss: 0.3952 - acc: 0.8306 - val_loss: 0.4292 - val_acc: 0.8038\n",
            "Epoch 7/100\n",
            "20000/20000 [==============================] - 25s 1ms/step - loss: 0.3852 - acc: 0.8320 - val_loss: 0.3931 - val_acc: 0.8254\n",
            "Epoch 8/100\n",
            "20000/20000 [==============================] - 25s 1ms/step - loss: 0.3728 - acc: 0.8425 - val_loss: 0.3955 - val_acc: 0.8248\n",
            "Epoch 9/100\n",
            "20000/20000 [==============================] - 25s 1ms/step - loss: 0.3658 - acc: 0.8450 - val_loss: 0.3841 - val_acc: 0.8302\n",
            "Epoch 10/100\n",
            "20000/20000 [==============================] - 25s 1ms/step - loss: 0.3582 - acc: 0.8497 - val_loss: 0.3944 - val_acc: 0.8264\n",
            "Epoch 11/100\n",
            "20000/20000 [==============================] - 25s 1ms/step - loss: 0.3657 - acc: 0.8466 - val_loss: 0.3832 - val_acc: 0.8314\n",
            "Epoch 12/100\n",
            "20000/20000 [==============================] - 25s 1ms/step - loss: 0.3651 - acc: 0.8447 - val_loss: 0.3704 - val_acc: 0.8412\n",
            "Epoch 13/100\n",
            "20000/20000 [==============================] - 25s 1ms/step - loss: 0.3566 - acc: 0.8518 - val_loss: 0.3761 - val_acc: 0.8356\n",
            "Epoch 14/100\n",
            "20000/20000 [==============================] - 25s 1ms/step - loss: 0.3458 - acc: 0.8566 - val_loss: 0.3747 - val_acc: 0.8370\n",
            "Epoch 15/100\n",
            "20000/20000 [==============================] - 25s 1ms/step - loss: 0.3436 - acc: 0.8566 - val_loss: 0.3594 - val_acc: 0.8464\n",
            "Epoch 16/100\n",
            "20000/20000 [==============================] - 25s 1ms/step - loss: 0.3370 - acc: 0.8586 - val_loss: 0.3649 - val_acc: 0.8418\n",
            "Epoch 17/100\n",
            "20000/20000 [==============================] - 25s 1ms/step - loss: 0.3305 - acc: 0.8639 - val_loss: 0.3563 - val_acc: 0.8480\n",
            "Epoch 18/100\n",
            "20000/20000 [==============================] - 25s 1ms/step - loss: 0.3354 - acc: 0.8603 - val_loss: 0.3839 - val_acc: 0.8308\n",
            "Epoch 19/100\n",
            "20000/20000 [==============================] - 25s 1ms/step - loss: 0.3277 - acc: 0.8643 - val_loss: 0.3714 - val_acc: 0.8400\n",
            "Epoch 20/100\n",
            "20000/20000 [==============================] - 25s 1ms/step - loss: 0.3220 - acc: 0.8682 - val_loss: 0.3646 - val_acc: 0.8454\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f843b6a5550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "Ta2KxeXXr7V2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Finally, we can check the performance of our trained network on the test set:**"
      ]
    },
    {
      "metadata": {
        "id": "iPXEZwpAkfP_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f51df054-0426-46a7-c75c-1164b0e86f81"
      },
      "cell_type": "code",
      "source": [
        "print('Accuracy on test set: {}'.format(model.evaluate(X_test, y_test,\n",
        "                                                       batch_size = batch_size)[1]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 10s 389us/step\n",
            "Accuracy on test set: 0.84936\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}