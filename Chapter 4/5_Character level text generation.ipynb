{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_Character-level text generation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "y2JoO1xbB95j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Let's start with importing the libraries as follows:**"
      ]
    },
    {
      "metadata": {
        "id": "0oydKO6BtX_k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "79d2ebae-4162-4006-db17-3934e0e8587b"
      },
      "cell_type": "code",
      "source": [
        "!pip install unidecode\n",
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from keras.datasets import reuters"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.0.23)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "v7ueu--wCHW_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**As input and output, we can use any character:**"
      ]
    },
    {
      "metadata": {
        "id": "nFquu2V2uboC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9dba56a0-be3d-4d10-b272-54441475ac06"
      },
      "cell_type": "code",
      "source": [
        "all_characters = string.printable\n",
        "input_size = len(all_characters)\n",
        "output_size = input_size\n",
        "print(input_size)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vzjvU4HUCQXV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**We need to define the hyperparameters before moving on:**"
      ]
    },
    {
      "metadata": {
        "id": "GNYPfuyvvKRP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_steps = 2000\n",
        "batch_size = 512\n",
        "hidden_size = 100\n",
        "n_layers = 2\n",
        "learning_rate = 0.01\n",
        "len_text = 200\n",
        "print_every = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AqxjfXa4CaPY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**We will be using the Reuters datasets from Keras**"
      ]
    },
    {
      "metadata": {
        "id": "Cu8GGcEgvupQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = reuters.load_data()\n",
        "\n",
        "len_data = len(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FaFG32LpCerj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Let's define a function that transforms characters to tensors:**"
      ]
    },
    {
      "metadata": {
        "id": "p9EIrBbTxN5x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def char_to_tensor(string):\n",
        "  tensor = torch.zeros(len(string)).long()\n",
        "  for c in range(len(string)):\n",
        "    try:\n",
        "      tensor[c] = all_characters.index(string[c])\n",
        "    except:\n",
        "      continue\n",
        "  return tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eICx89LCCofE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Next, we define a batch generator:**"
      ]
    },
    {
      "metadata": {
        "id": "TZnMSP2Q3_xI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def batch_gen(length_text, batch_size):\n",
        "  X = torch.LongTensor(batch_size, length_text)\n",
        "  y = torch.LongTensor(batch_size, length_text)\n",
        "  for i in range(batch_size):\n",
        "    start_index = random.randint(0, len_data - length_text)\n",
        "    end_index = start_index + length_text + 1\n",
        "    text = data[start_index : end_index]\n",
        "    X[i] = char_to_tensor(text[:-1])\n",
        "    y[i] = char_to_tensor(text[1:])\n",
        "    X = Variable(X)\n",
        "    y = Variable(y)\n",
        "    X = X.cuda()\n",
        "    y = y.cuda()\n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RUR4xsRsCubZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**We are now ready to define our network architecture:**"
      ]
    },
    {
      "metadata": {
        "id": "IJpj6jA64mCz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class create_model(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, n_layers = 1):\n",
        "    super(create_model, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.n_layers = n_layers\n",
        "    self.encoder = nn.Embedding(input_size, hidden_size)\n",
        "    self.rnn = nn.GRU(hidden_size, hidden_size, n_layers)\n",
        "    self.decoder = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "  def forward(self, input, hidden):\n",
        "    batch_size = input.size(0)\n",
        "    encoded = self.encoder(input)\n",
        "    output, hidden = self.rnn(encoded.view(1, batch_size, -1), hidden)\n",
        "    output = self.decoder(output.view(batch_size, -1))\n",
        "    return output, hidden\n",
        "    \n",
        "  def init_hidden(self, batch_size):\n",
        "    return Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fR9mfhGSC2bu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**We continue by creating our model and defining the optimizer and loss function as follows:**"
      ]
    },
    {
      "metadata": {
        "id": "cRxootPs74Ra",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "d8230dbd-4dc7-426f-f20d-4527533a9e17"
      },
      "cell_type": "code",
      "source": [
        "decoder_model = create_model(\n",
        "    input_size,\n",
        "    hidden_size,\n",
        "    output_size,\n",
        "    n_layers = n_layers,\n",
        ")\n",
        "\n",
        "opt = torch.optim.Adam(decoder_model.parameters(), \n",
        "                       lr = learning_rate)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "decoder_model.cuda()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "create_model(\n",
              "  (encoder): Embedding(100, 100)\n",
              "  (rnn): GRU(100, 100, num_layers=2)\n",
              "  (decoder): Linear(in_features=100, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "Ms0wOudnDBVT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**We also create a function that we can use to generate text during training:**"
      ]
    },
    {
      "metadata": {
        "id": "vfg8MNhd8pLq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_text(decoder, start = 'The', predict_len = 100):\n",
        "  hidden = decoder.init_hidden(1).cuda()\n",
        "  prime_input = Variable(char_to_tensor(start).unsqueeze(0)).cuda()\n",
        "  predicted = start\n",
        "  \n",
        "  for p in range(len(start) - 1):\n",
        "    _, hidden = decoder(prime_input[:, p], hidden)\n",
        "    \n",
        "  x = prime_input[:, -1]\n",
        "  \n",
        "  for p in range(predict_len):\n",
        "    output, hidden = decoder(x, hidden)\n",
        "    output_dist = output.data.view(-1).div(0.8).exp()\n",
        "    \n",
        "    # Add some randomness\n",
        "    top_i = torch.multinomial(output_dist, 1)[0]\n",
        "    predicted_char = all_characters[top_i]\n",
        "    predicted += predicted_char\n",
        "    x = Variable(char_to_tensor(predicted_char).unsqueeze(0)).cuda()\n",
        "    \n",
        "  return predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rRthXJq8DMfI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Finally, let's start training:**"
      ]
    },
    {
      "metadata": {
        "id": "dnppRMks9x4S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "outputId": "a30f8eaf-fd4f-49b9-edbb-b14d2d2fb8fc"
      },
      "cell_type": "code",
      "source": [
        "loss_avg = 0\n",
        "\n",
        "for i in range(n_steps):\n",
        "  X, y = batch_gen(len_text, batch_size)\n",
        "  hidden = decoder_model.init_hidden(batch_size).cuda()\n",
        "  decoder_model.zero_grad()\n",
        "  loss_total = 0\n",
        "  \n",
        "  for c in range(len_text):\n",
        "    output, hidden = decoder_model(X[:, c], hidden)\n",
        "    loss_total += loss(output.view(batch_size, -1), y[:, c])\n",
        "    \n",
        "  loss_total.backward()\n",
        "  opt.step()\n",
        "  loss_value = loss_total.data[0] / len_text\n",
        "  \n",
        "  loss_avg += loss_value\n",
        "  \n",
        "  if i % print_every == 0:\n",
        "    print('Epoch {}: loss {}'.format(i, loss_avg))\n",
        "    print(generate_text(decoder_model, 'The', 100), '\\n')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-e1233be8dffb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-fc2958d1d057>\u001b[0m in \u001b[0;36mbatch_gen\u001b[0;34m(length_text, batch_size)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mstart_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_data\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlength_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mend_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlength_text\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_index\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mend_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/random.py\u001b[0m in \u001b[0;36mrandint\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \"\"\"\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     def _randbelow(self, n, int=int, maxsize=1<<BPF, type=type,\n",
            "\u001b[0;32m/usr/lib/python3.6/random.py\u001b[0m in \u001b[0;36mrandrange\u001b[0;34m(self, start, stop, step, _int)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mistart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"empty range for randrange() (%d,%d, %d)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mistart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mistop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;31m# Non-unit step argument supplied.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: empty range for randrange() (0,-197, -197)"
          ]
        }
      ]
    }
  ]
}