{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_Implementing a deep Q-learning algorithm.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "6VIyNLZrBi9R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Let's start with importing the necessary libraries, as follows:**"
      ]
    },
    {
      "metadata": {
        "id": "IWja6bvLytfX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ba68eb80-c2b0-4422-aaa0-48e97acb8585"
      },
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "X3Hn_553B1sy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**First, we will plot an example input image of the game:**"
      ]
    },
    {
      "metadata": {
        "id": "iTVywF8s_8i8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "2bbc7ede-c48e-40d0-f8d0-5bb4f3885e5a"
      },
      "cell_type": "code",
      "source": [
        "env = gym.make('BreakoutDeterministic-v4')\n",
        "observation = env.reset()\n",
        "\n",
        "for i in range(3):\n",
        "  # The ball is released after 2 frames\n",
        "  if i > 1:\n",
        "    print(observation.shape)\n",
        "    plt.imshow(observation)\n",
        "    plt.show()\n",
        "    \n",
        "  # Get the next observation\n",
        "  observation, _, _, _ = env.step(1)\n",
        "\n",
        "  \n",
        "## Example input image of Breakout by OpenAI"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(210, 160, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAFNCAYAAAD4liEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMPpvLhMV0tBYcycAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "XOoxdzXGCK2j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Now, we can define a function that preprocesses the input data:**"
      ]
    },
    {
      "metadata": {
        "id": "UQbaqMsHA3_C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess_frame(frame):\n",
        "  frame = frame[30:200, 10:150]\n",
        "  \n",
        "  # grayscale frame and downsize by factor 2\n",
        "  frame = frame[::2, ::2, 0]\n",
        "  \n",
        "  # set background to 0\n",
        "  frame[frame == 144] = 0\n",
        "  frame[frame == 109] = 0\n",
        "  \n",
        "  # set ball and paddles to 1\n",
        "  frame[frame != 0] = 1\n",
        "  \n",
        "  return frame"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FooyrkOjCRKW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Let's output the preceding preprocessed image to give us an idea of what our algorithm will process:**"
      ]
    },
    {
      "metadata": {
        "id": "xmQlAWIoChSS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "e0c71c34-784b-41c4-e740-a6a88a446b8f"
      },
      "cell_type": "code",
      "source": [
        "obs_preprocessed = preprocess_frame(observation)\n",
        "\n",
        "plt.imshow(obs_preprocessed, cmap = 'gray')\n",
        "plt.show()\n",
        "\n",
        "## Preprocessed frame of Breakout"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARYAAAFMCAYAAAAOWJPeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFQ5JREFUeJzt3X9sVYX9//HX/fb2pmnBAdfeYo2g\nIwpkLf5I9kcrrTZlLGXLNkm2dA2SbYGJtUiyQdtVhjoSKz8kzrqI48c/TgdbMazJ2Nr4RxOzXK7B\nGVaMiyl/LFDL9bYC5UdvpZfz+cPRyL4HzhXf995z8flISNrbS++LW3x6z+2lJ+A4jiMAMPT/cj0A\nwM2HsAAwR1gAmCMsAMwRFgDmCAsAc8Eb/Y3PPfecjh49qkAgoI6ODi1atMhyF4A8dkNheeedd/Sf\n//xH+/fv1/Hjx9XR0aH9+/dbbwOQp27oUCgajWrJkiWSpHnz5uns2bM6f/686TAA+euGwjIyMqKZ\nM2dOvT9r1iwlEgmzUQDym8mTt/yrAACfd0NhiUQiGhkZmXr/448/VmlpqdkoAPnthp68ffDBB9XV\n1aXGxka9//77ikQimjZt2jWvHwgEJH32yObK27nmpy2Sv/awxR1b3He4uaGwPPDAA/rGN76hxsZG\nBQIBPf30019qHICbSyAbPzaBRyze/LSHLe7Y4r7DDa+8BWCOsAAwR1gAmCMsAMwRFgDmCAsAc4QF\ngDnCAsAcYQFgjrAAMEdYAJgjLADMERYA5ggLAHOEBYA5wgLAHGEBYI6wADBHWACYIywAzBEWAOYI\nCwBzhAWAOcICwBxhAWCOsAAwl1ZYPvzwQy1ZskR/+MMfJEnDw8N69NFH1dTUpHXr1unTTz/N6EgA\n+cUzLBcvXtTmzZtVVVU1ddlLL72kpqYmvfHGG5o7d666u7szOhJAfvEMSygU0q5duxSJRKYui8Vi\nqq+vlyTV1dUpGo1mbiGAvBP0vEIwqGDw6quNj48rFApJksLhsBKJRGbWAchLnmHx4jiO53UGBgZU\nUVGR9vWzxU9bJH/tYYs7tqTnhsJSXFysZDKpoqIixePxqw6T3FRWVkr67I4IBAI3cpPm/LRF8tce\ntrhji/sONzf07ebq6mr19vZKkvr6+lRTU3PjywDcdAKOx+OpY8eOacuWLRoaGlIwGFRZWZm2b9+u\n9vZ2TUxMqLy8XJ2dnSosLLz2jfy3rH6prOSvLZK/9rDFHVvcd7jxDIsFwuLNT3vY4o4t7jvc8Mpb\nAOYICwBzhAWAOcICwBxhAWCOsAAwR1gAmMvK61gAfLXwiAWAOcICwBxhAWCOsAAwR1gAmCMsAMwR\nFgDmCAsAc4QFgDnCAsAcYQFgjrAAMEdYAJgjLADMERYA5ggLAHOEBYA5wgLAHGEBYC6YzpW2bt2q\nd999V5OTk3rsscdUWVmp1tZWpVIplZaWatu2bQqFQpneCiBPeP4w7cOHD2vPnj3atWuXTp8+rUce\neURVVVWqra1VQ0ODduzYodmzZ6upqSlbmwH4nGdYUqmUJiYmVFxcrFQqperqapWUlOjvf/+7QqGQ\n3nvvPe3du1ddXV3Z2gzA5zyfYykoKFBxcbEkqbu7W7W1tRofH5869AmHw0okEpldCSCvpP3k7Vtv\nvaXu7m5t2rTpqss5LRGA/5VWWN5++23t3LlTu3bt0vTp01VcXKxkMilJisfjikQiGR0JIL94huXc\nuXPaunWrXn31Vc2YMUOSVF1drd7eXklSX1+fampqMrsSQF7xfPJ2//796urq0l133TV12fPPP6+N\nGzdqYmJC5eXl6uzsVGFhYcbHAsgPnLsZgDleeQvAHGEBYI6wADBHWACYIywAzBEWAOYICwBzhAWA\nOcICwBxhAWCOsAAwR1gAmCMsAMwRFgDmCAsAc4QFgDnCAsAcYQFgjrAAMEdYAJgjLADMERYA5ggL\nAHOEBYA5wgLAHGEBYC7odYXx8XG1t7drdHRUExMTam5u1oIFC9Ta2qpUKqXS0lJt27ZNoVAoG3sB\n5AHPczcfOnRIQ0NDWr16tYaGhvSzn/1MDzzwgGpra9XQ0KAdO3Zo9uzZampqytZmAD7neSi0bNky\nrV69WpI0PDyssrIyxWIx1dfXS5Lq6uoUjUYzuxJAXvE8FLqisbFRp06d0s6dO/XTn/506tAnHA4r\nkUhkbCCA/JN2WPbt26cPPvhAGzZs0OePnjyOpAB8BXkeCh07dkzDw8OSpIULFyqVSqmkpETJZFKS\nFI/HFYlEMrsSQF7xDMuRI0e0d+9eSdLIyIguXryo6upq9fb2SpL6+vpUU1OT2ZUA8ornd4WSyaSe\neuopDQ8PK5lMqqWlRRUVFWpra9PExITKy8vV2dmpwsLCbG0G4HOeYQGALyrtJ2+/jEAgIOmzJ3qv\nvJ1rftoi+WsPW9yxxX2HG17SD8AcYQFgjrAAMEdYAJgjLADMERYA5ggLAHOEBYA5wgLAHGEBYI6w\nADBHWACYIywAzBEWAOYICwBzhAWAOcICwBxhAWCOsAAwR1gAmCMsAMwRFgDmCAsAc4QFgDnCAsBc\nWmFJJpNasmSJ3nzzTQ0PD+vRRx9VU1OT1q1bp08//TTTGwHkmbTC8sorr+hrX/uaJOmll15SU1OT\n3njjDc2dO1fd3d0ZHQgg/3iG5fjx4xocHNTDDz8sSYrFYqqvr5ck1dXVKRqNZnQggPzjeVL4LVu2\n6Ne//rUOHjwoSRofH1coFJIkhcNhJRIJzxsZGBhQRUWFpGufRDoX/LRF8tcetrhjS3quG5aDBw/q\nvvvu0x133OH68XT/YJWVlVPXDwQCX3BiZvhpi+SvPWxxxxb3HW6uG5b+/n6dOHFC/f39OnXqlEKh\nkIqLi5VMJlVUVKR4PK5IJJKRwQDy13XD8uKLL0693dXVpdtvv13vvfeeent79f3vf199fX2qqanJ\n+EgA+eULv45l7dq1OnjwoJqamnTmzBn94Ac/yMQuAHks4GThGaArx4J+OS6U/LVF8tcetrhji/sO\nN7zyFoA5wgLAHGEBYI6wADBHWACYIywAzBEWAOYICwBzhAWAOcICwBxhAWCOsAAwR1gAmCMsAMwR\nFgDmCAsAc4QFgDnCAsAcYQFgjrAAMEdYAJgjLADMERYA5ggLAHOEBYA5wgLA3HVPCi9JsVhM69at\n09133y1Juueee7Rq1Sq1trYqlUqptLRU27ZtUygUyvhYAHnC8XD48GFn7dq1V13W3t7uHDp0yHEc\nx3nhhRec119//bqfQ5Jz5aauvJ3rX37a4rc9bGHLF9nh5oYOhWKxmOrr6yVJdXV1ikajN/JpANyk\nPA+FJGlwcFBr1qzR2bNn1dLSovHx8alDn3A4rEQicd3fPzAwoIqKCkm65tnpc8FPWyR/7WGLO7ak\nxzMsd955p1paWtTQ0KATJ05o5cqVSqVSUx9P5w9XWVk5dd1AIPAl5trx0xbJX3vY4o4t7jvceB4K\nlZWVadmyZQoEApozZ45uvfVWnT17VslkUpIUj8cViURs1wLIa55h6enp0Z49eyRJiURCo6OjWr58\nuXp7eyVJfX19qqmpyexKAHkl4Hgcy5w/f17r16/X2NiYLl26pJaWFi1cuFBtbW2amJhQeXm5Ojs7\nVVhYeO0b+e9DNr88fJP8tUXy1x62uGOL+w43nmGxQFi8+WkPW9yxxX2Hm7S+K4Sb0//+pfDDX1Tc\nHHhJPwBzhAWAOcICwBxhAWCOsAAwR1gAmOPbzV9hfHsZmcIjFgDmCAsAc4QFgDnCAsAcYQFgjrAA\nMEdYAJgjLADMERYA5ggLAHOEBYA5wgLAHGEBYI6wADBHWACYIywAzBEWAOYICwBzaf1oyp6eHu3e\nvVvBYFBPPvmk5s+fr9bWVqVSKZWWlmrbtm0KhUKZ3gogT3ieu/n06dNqbGzUgQMHdPHiRXV1dWly\nclK1tbVqaGjQjh07NHv2bDU1NV37Rjh3syc/7WGLO7a473DjeSgUjUZVVVWladOmKRKJaPPmzYrF\nYqqvr5ck1dXVKRqN2q4FkNc8D4VOnjypZDKpNWvWaGxsTGvXrtX4+PjUoU84HFYikcj4UAD5I63n\nWM6cOaOXX35ZH330kVauXHnVwx+PIylJ0sDAgCoqKtK+frb4aYvkrz1scceW9HiGJRwO6/7771cw\nGNScOXNUUlKigoICJZNJFRUVKR6PKxKJXPdzVFZWSvLPcaHkry2Sv/awxR1b3He48XyOZfHixTp8\n+LAuX76s06dP6+LFi6qurlZvb68kqa+vTzU1NbZrAeQ1z+8KSdK+ffvU3d0tSXr88cdVWVmptrY2\nTUxMqLy8XJ2dnSosLLz2jfBdIU9+2sMWd2xx3+EmrbB8WYTFm5/2sMUdW9x3uOGVtwDMERYA5ggL\nAHOEBYA5wgLAHGEBYI6wADBHWACYIywAzBEWAOYICwBzhAWAOcICwBxhAWCOsAAwR1gAmCMsAMwR\nFgDmCAsAc4QFgDnCAsAcYQFgjrAAMEdYAJgjLADMERYA5oJeV/jzn/+snp6eqfePHTumP/7xj3rm\nmWckSfPnz9ezzz6bsYEA8s8XOnfzO++8o7/97W8aHBzUhg0btGjRIv3yl7/U9773PT300EPXvhHO\n3ezJT3vY4o4t7jvcfKFDod/97ndavXq1hoaGtGjRIklSXV2dotHol18I4KaRdlj+9a9/6bbbblNB\nQYFuueWWqcvD4bASiURGxgHIT57PsVzR3d2tRx555P+7PJ0jqYGBAVVUVKR9/Wzx0xbJX3vY4o4t\n6Uk7LLFYTBs3blQgENCZM2emLo/H44pEItf9vZWVlZL8c1wo+WuL5K89bHHHFvcdbtI6FIrH4yop\nKVEoFFJhYaG+/vWv68iRI5Kkvr4+1dTU2C0FkPfSesSSSCQ0a9asqfc7Ojq0adMmXb58Wffee6+q\nq6szNhBA/vlC326+4Rvh282e/LSHLe7Y4r7DDa+8BWCOsAAwR1gAmCMsAMwRFgDmCAsAc4QFgDnC\nAsAcYQFgjrAAMEdYAJgjLADMERYA5ggLAHOEBYA5wgLAHGEBYI6wADBHWACYIywAzBEWAOYICwBz\nhAWAOcICwBxhAWCOsAAwR1gAmPM8KfyFCxfU1tams2fP6tKlS3riiSdUWlqqZ555RpI0f/58Pfvs\ns5neCSCfOB5ee+01Z/v27Y7jOM6pU6ecb3/7286KFSuco0ePOo7jOL/4xS+c/v7+634OSc6Vm7ry\ndq5/+WmL3/bcTFuyLV/uF8sdbjwPhWbOnKkzZ85IksbGxjRjxgwNDQ1p0aJFkqS6ujpFo1GvTwPg\nK8TzUOg73/mO3nzzTX3rW9/S2NiYXnnlFf3mN7+Z+ng4HFYikbju5xgYGFBFRYUk6bPQ+oOftkj+\n2sOWG5PNrX6+XzzD8pe//EXl5eXas2eP/v3vf+uJJ57Q9OnTpz6ezh+usrJy6rqBQOBLzLXjpy2S\nv/bcTFuy/R9ftu43v3yNrnX/eobln//8pxYvXixJWrBggSYmJjQ5OTn18Xg8rkgkYjQTwM3A8zmW\nuXPn6ujRo5KkoaEhlZSUaN68eTpy5Igkqa+vTzU1NZldCSCvBByPx4oXLlxQR0eHRkdHNTk5qXXr\n1qm0tFSbNm3S5cuXde+99+pXv/rV9W/kvw/Z/PLwTfLXFslfe26mLRwKZX6HG8+wWCAs3vy0hy3u\n2OK+ww2vvAVgjrAAMEdYAJgjLADMERYA5ggLAHOEBYA5wgLAHGEBYI6wADCXlZf0A/hq4RELAHOE\nBYA5wgLAHGEBYI6wADBHWACY8/xh2laee+45HT16VIFAQB0dHVPnJcqWDz/8UM3NzfrJT36iFStW\naHh4WK2trUqlUiotLdW2bdsUCoWysmXr1q169913NTk5qccee0yVlZU52TI+Pq729naNjo5qYmJC\nzc3NWrBgQc7ulyuSyaS++93vqrm5WVVVVTnZE4vFtG7dOt19992SpHvuuUerVq3K2X3T09Oj3bt3\nKxgM6sknn9T8+fNz/nW6ri9/7jdvsVjM+fnPf+44juMMDg46P/rRj7Jxs1MuXLjgrFixwtm4caPz\n2muvOY7jOO3t7c6hQ4ccx3GcF154wXn99dezsiUajTqrVq1yHMdxPvnkE+ehhx7K2Za//vWvzu9/\n/3vHcRzn5MmTztKlS3O25fN27NjhLF++3Dlw4EDO9hw+fNhZu3btVZflassnn3ziLF261Dl37pwT\nj8edjRs3+uLrdD1ZORSKRqNasmSJJGnevHk6e/aszp8/n42bliSFQiHt2rXrqtOUxGIx1dfXS8ru\n2Ry/+c1v6re//a0k6ZZbbtH4+HjOtixbtkyrV6+WJA0PD6usrCxnW644fvy4BgcH9fDDD0vK3dfJ\nTa62RKNRVVVVadq0aYpEItq8ebOv7hc3WQnLyMiIZs6cOfX+rFmzPM+eaCkYDKqoqOiqy8bHx6ce\nOqZzNkcrBQUFKi4uliR1d3ertrY2Z1uuaGxs1Pr169XR0ZHzLVu2bFF7e/vU+7ncMzg4qDVr1ujH\nP/6x/vGPf+Rsy8mTJ5VMJrVmzRo1NTUpGo3m/OvkJWvPsXye47N/RZCLPW+99Za6u7u1d+9eLV26\nNKdb9u3bpw8++EAbNmy46vazveXgwYO67777dMcdd7h+PJt77rzzTrW0tKihoUEnTpzQypUrlUql\ncrJFks6cOaOXX35ZH330kVauXJnTr1M6shKWSCSikZGRqfc//vhjlZaWZuOmr6m4uFjJZFJFRUVZ\nP5vj22+/rZ07d2r37t2aPn16zrYcO3ZM4XBYt912mxYuXKhUKqWSkpKc3S/9/f06ceKE+vv7derU\nKYVCoZzdN2VlZVq2bJkkac6cObr11ls1MDCQky3hcFj333+/gsGg5syZo5KSEhUUFOTs65SOrBwK\nPfjgg+rt7ZUkvf/++4pEIpo2bVo2bvqaqqurpzZl82yO586d09atW/Xqq69qxowZOd1y5MgR7d27\nV9Jnh6sXL17M2RZJevHFF3XgwAH96U9/0g9/+EM1NzfnbE9PT4/27NkjSUokEhodHdXy5ctzsmXx\n4sU6fPiwLl++rNOnT+f865SOrP3r5u3bt+vIkSMKBAJ6+umntWDBgmzcrKTP/s+8ZcsWDQ0NKRgM\nqqysTNu3b1d7e7smJiZUXl6uzs5OFRYWZnzL/v371dXVpbvuumvqsueff14bN27M+pZkMqmnnnpK\nw8PDSiaTamlpUUVFhdra2rK+5X91dXXp9ttv1+LFi3Oy5/z581q/fr3GxsZ06dIltbS0aOHChTm7\nb/bt26fu7m5J0uOPP67KykpffJ2uhR+bAMAcr7wFYI6wADBHWACYIywAzBEWAOYICwBzhAWAOcIC\nwNz/AcB1irsqy3TOAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Yq7lzwapCnCi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**For our deep Q-learning implementation, we need to define an agent that performs most of the tasks:**"
      ]
    },
    {
      "metadata": {
        "id": "v4l4TQ8hC63b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DQLAgent:\n",
        "  def __init__(self, cols, rows, n_actions, batch_size = 32):\n",
        "    self.state_size = (cols, rows, 4)\n",
        "    self.n_actions = n_actions\n",
        "    self.epsilon = 1.\n",
        "    self.epsilon_start, self.epsilon_end = 1.0, 0.1\n",
        "    self.exploration_steps = 1000000.\n",
        "    self.epsilon_decay_step = (self.epsilon_start - self.epsilon_end) / self.exploration_steps\n",
        "    self.batch_size = batch_size\n",
        "    self.discount_factor = 0.99\n",
        "    self.memory = deque(maxlen = 400000)\n",
        "    self.model = self.build_model()\n",
        "    self.target_model = self.build_model()\n",
        "    self.optimizer = self.optimizer()\n",
        "    self.avg_q_max, self.avg_loss = 0, 0\n",
        "    \n",
        "  \n",
        "  def optimizer(self):\n",
        "    a = K.placeholder(shape = (None, ), dtype = 'int32')\n",
        "    y = K.placeholder(shape = (None, ), dtype = 'float32')\n",
        "    \n",
        "    py_x = self.model.output\n",
        "    \n",
        "    a_one_hot = K.one_hot(a, self.n_actions)\n",
        "    q_value = K.sum(py_x * a_one_hot, axis = 1)\n",
        "    error = K.abs(y - q_value)\n",
        "    \n",
        "    quadratic_part = K.clip(error, 0.0, 1.0)\n",
        "    linear_part = error - quadratic_part\n",
        "    loss = K.mean(0.5 * K.square(quadratic_part) + linear_part)\n",
        "    \n",
        "    opt = Adam(lr = 0.00025, epsilon = 0.01)\n",
        "    updates = opt.get_updates(self.model.trainable_weights, [], loss)\n",
        "    train = K.function([self.model.input, a, y], [loss], \n",
        "                       updates = updates)\n",
        "    \n",
        "    return train\n",
        "  \n",
        "  \n",
        "  def build_model(self):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (8, 8), strides = (4, 4), activation = 'relu', input_shape = self.state_size))\n",
        "    model.add(Conv2D(64, (4, 4), strides = (2, 2), activation = 'relu'))\n",
        "    model.add(Conv2D(64, (3, 3), strides = (1, 1), activation = 'relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation = 'relu'))\n",
        "    model.add(Dense(self.n_actions))\n",
        "    model.summary()\n",
        "    return model\n",
        "  \n",
        "  \n",
        "  def update_model(self):\n",
        "    self.target_model.set_weights(self.model.get_weights())\n",
        "    \n",
        "  \n",
        "  def action(self, history):\n",
        "    history = np.float32(history / 255.0)\n",
        "    if np.random.rand() <= self.epsilon:\n",
        "      return random.randrange(self.n_actions)\n",
        "    else:\n",
        "      q_value = self.model.predict(history)\n",
        "      return np.argmax(q_value[0])\n",
        "    \n",
        "  \n",
        "  def replay(self, history, action, reward, next_history, dead):\n",
        "    self.memory.append((history, action, reward, next_history, dead))\n",
        "    \n",
        "  \n",
        "  def train(self):\n",
        "    if len(self.memory) < self.batch_size:\n",
        "      return\n",
        "    if self.epsilon > self.epsilon_end:\n",
        "      self.epsilon -= self.epsilon_decay_step\n",
        "      \n",
        "    mini_batch = random.sample(self.memory, self.batch_size)\n",
        "    history = np.zeros((self.batch_size, self.state_size[0],\n",
        "                        self.state_size[1], self.state_size[2]))\n",
        "    next_history = np.zeros((self.batch_size, self.state_size[0],\n",
        "                             self.state_size[1], self.state_size[2]))\n",
        "    target = np.zeros((self.batch_size, ))\n",
        "    action, reward, dead = [], [], []\n",
        "    \n",
        "    for i in range(self.batch_size):\n",
        "      history[i] = np.float32(mini_batch[i][0] / 255.)\n",
        "      next_history[i] = np.float32(mini_batch[i][3] / 255.)\n",
        "      action.append(mini_batch[i][1])\n",
        "      reward.append(mini_batch[i][2])\n",
        "      dead.append(mini_batch[i][4])\n",
        "      \n",
        "    target_value = self.target_model.predict(next_history)\n",
        "    \n",
        "    for i in range(self.batch_size):\n",
        "      if dead[i]:\n",
        "        target[i] = reward[i]\n",
        "      else: \n",
        "        target[i] = reward[i] + self.discount_factor * np.amax(target_value[i])\n",
        "        \n",
        "    loss = self.optimizer([history, action, target])\n",
        "    self.avg_loss += loss[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ybrUdyPeC1Jb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Next, we set the hyperparameters and some general settings and initialize our agent:**"
      ]
    },
    {
      "metadata": {
        "id": "wLaymC7DQ2Ww",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "outputId": "5c451e81-4464-4554-a71f-b29558e9a5d5"
      },
      "cell_type": "code",
      "source": [
        "env = gym.make('BreakoutDeterministic-v4')\n",
        "\n",
        "# General settings\n",
        "n_warmup_steps = 50000\n",
        "update_model_rate = 10000\n",
        "cols, rows = 85, 70\n",
        "n_states = 4\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 32\n",
        "\n",
        "# Initialization\n",
        "agent = DQLAgent(cols, rows, n_actions = 3)\n",
        "scores, episodes = [], []\n",
        "n_steps = 0"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 20, 16, 32)        8224      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 9, 7, 64)          32832     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 7, 5, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2240)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1147392   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 1539      \n",
            "=================================================================\n",
            "Total params: 1,226,915\n",
            "Trainable params: 1,226,915\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 20, 16, 32)        8224      \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 9, 7, 64)          32832     \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 7, 5, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2240)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               1147392   \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 1539      \n",
            "=================================================================\n",
            "Total params: 1,226,915\n",
            "Trainable params: 1,226,915\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ae8gOssKDEVM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**We are now ready to start training our model:**"
      ]
    },
    {
      "metadata": {
        "id": "qqHNpokxT-Ni",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10856
        },
        "outputId": "c62f84df-8f07-4294-accd-e9fec186f243"
      },
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  done = False\n",
        "  dead = False\n",
        "  step, score, start_life = 0, 0, 5\n",
        "  observation = env.reset()\n",
        "  \n",
        "  state = preprocess_frame(observation).reshape(cols, rows)\n",
        "  history = np.stack((state, state, state, state), axis = 2)\n",
        "  history = np.reshape([history], (1, cols, rows, n_states))\n",
        "  \n",
        "  while not done:\n",
        "    # env.render()\n",
        "    n_steps += 1\n",
        "    step += 1\n",
        "    \n",
        "    # Get action\n",
        "    action = agent.action(history)\n",
        "    observation, reward, done, info = env.step(action + 1)\n",
        "    \n",
        "    # Extract next state\n",
        "    state_next = preprocess_frame(observation).reshape(cols, rows)\n",
        "    state_next = np.reshape([state_next], (1, cols, rows, 1))\n",
        "    history_next = np.append(state_next, history[:, :, :, :3], axis = 3)\n",
        "    \n",
        "    agent.avg_q_max += np.amax(agent.model.predict(history)[0])\n",
        "    reward = np.clip(reward, -1., 1.)\n",
        "    \n",
        "    agent.replay(history, action, reward, history_next, dead)\n",
        "    agent.train()\n",
        "    \n",
        "    if n_steps % update_model_rate == 0:\n",
        "      agent.update_model()\n",
        "    score += reward\n",
        "    \n",
        "    if dead:\n",
        "      dead = False\n",
        "    else:\n",
        "      history = history_next\n",
        "      \n",
        "    if done:\n",
        "      print('episode {:2d}; score: {:2.0f}; q {:2f}; loss {:2f}; steps {}'\n",
        "            .format(n_steps, score, agent.avg_q_max / float(step), agent.avg_loss / float(step), step))\n",
        "      \n",
        "      agent.avg_q_max, agent.avg_loss = 0, 0\n",
        "      \n",
        "  # Save weights of model\n",
        "  if n_steps % 1000 == 0:\n",
        "    agent.model.save_weights(\"breakout_dql.h5\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "episode 256; score:  3; q 0.113287; loss 0.004394; steps 255\n",
            "episode 412; score:  1; q 0.113409; loss 0.005049; steps 156\n",
            "episode 546; score:  0; q 0.111289; loss 0.003920; steps 134\n",
            "episode 674; score:  0; q 0.113497; loss 0.003868; steps 128\n",
            "episode 908; score:  3; q 0.113190; loss 0.003898; steps 234\n",
            "episode 1078; score:  1; q 0.113888; loss 0.003729; steps 170\n",
            "episode 1205; score:  0; q 0.111518; loss 0.004257; steps 127\n",
            "episode 1531; score:  5; q 0.119345; loss 0.002856; steps 326\n",
            "episode 1690; score:  1; q 0.119563; loss 0.004187; steps 159\n",
            "episode 1893; score:  2; q 0.122206; loss 0.005254; steps 203\n",
            "episode 2103; score:  2; q 0.121653; loss 0.003697; steps 210\n",
            "episode 2264; score:  1; q 0.118511; loss 0.003759; steps 161\n",
            "episode 2394; score:  0; q 0.116914; loss 0.004397; steps 130\n",
            "episode 2566; score:  1; q 0.118428; loss 0.003794; steps 172\n",
            "episode 2694; score:  0; q 0.119649; loss 0.004360; steps 128\n",
            "episode 2867; score:  1; q 0.115643; loss 0.003409; steps 173\n",
            "episode 3046; score:  1; q 0.120420; loss 0.004070; steps 179\n",
            "episode 3252; score:  2; q 0.125792; loss 0.004435; steps 206\n",
            "episode 3412; score:  1; q 0.122360; loss 0.003201; steps 160\n",
            "episode 3541; score:  0; q 0.117371; loss 0.003845; steps 129\n",
            "episode 3674; score:  0; q 0.116240; loss 0.002462; steps 133\n",
            "episode 3800; score:  0; q 0.115244; loss 0.003818; steps 126\n",
            "episode 3930; score:  0; q 0.116092; loss 0.003106; steps 130\n",
            "episode 4204; score:  4; q 0.131154; loss 0.003060; steps 274\n",
            "episode 4327; score:  0; q 0.117247; loss 0.004161; steps 123\n",
            "episode 4450; score:  0; q 0.119137; loss 0.004409; steps 123\n",
            "episode 4605; score:  1; q 0.121019; loss 0.004198; steps 155\n",
            "episode 4774; score:  1; q 0.122140; loss 0.003218; steps 169\n",
            "episode 4928; score:  1; q 0.129595; loss 0.003528; steps 154\n",
            "episode 5088; score:  1; q 0.123857; loss 0.002433; steps 160\n",
            "episode 5219; score:  0; q 0.118401; loss 0.004260; steps 131\n",
            "episode 5348; score:  0; q 0.117172; loss 0.002534; steps 129\n",
            "episode 5553; score:  2; q 0.119874; loss 0.004008; steps 205\n",
            "episode 5711; score:  1; q 0.116767; loss 0.003437; steps 158\n",
            "episode 5845; score:  0; q 0.116099; loss 0.002209; steps 134\n",
            "episode 6034; score:  2; q 0.120664; loss 0.003778; steps 189\n",
            "episode 6170; score:  0; q 0.116665; loss 0.002518; steps 136\n",
            "episode 6402; score:  3; q 0.105549; loss 0.004208; steps 232\n",
            "episode 6581; score:  1; q 0.119297; loss 0.003555; steps 179\n",
            "episode 6812; score:  2; q 0.117298; loss 0.003158; steps 231\n",
            "episode 7030; score:  2; q 0.118553; loss 0.002212; steps 218\n",
            "episode 7168; score:  0; q 0.115597; loss 0.003150; steps 138\n",
            "episode 7347; score:  1; q 0.115492; loss 0.003471; steps 179\n",
            "episode 7486; score:  0; q 0.119033; loss 0.002463; steps 139\n",
            "episode 7701; score:  2; q 0.124231; loss 0.003468; steps 215\n",
            "episode 7838; score:  0; q 0.116381; loss 0.003061; steps 137\n",
            "episode 8016; score:  1; q 0.118937; loss 0.002534; steps 178\n",
            "episode 8143; score:  0; q 0.116477; loss 0.002326; steps 127\n",
            "episode 8314; score:  1; q 0.112055; loss 0.002094; steps 171\n",
            "episode 8514; score:  2; q 0.124867; loss 0.003413; steps 200\n",
            "episode 8695; score:  1; q 0.116829; loss 0.003432; steps 181\n",
            "episode 8882; score:  1; q 0.121229; loss 0.004222; steps 187\n",
            "episode 9054; score:  1; q 0.117930; loss 0.003344; steps 172\n",
            "episode 9182; score:  0; q 0.118717; loss 0.003758; steps 128\n",
            "episode 9314; score:  0; q 0.117370; loss 0.003758; steps 132\n",
            "episode 9516; score:  2; q 0.122134; loss 0.002236; steps 202\n",
            "episode 9648; score:  0; q 0.119391; loss 0.003412; steps 132\n",
            "episode 9779; score:  0; q 0.120103; loss 0.003438; steps 131\n",
            "episode 9996; score:  2; q 0.122282; loss 0.002649; steps 217\n",
            "episode 10129; score:  0; q 0.117095; loss 0.002585; steps 133\n",
            "episode 10348; score:  2; q 0.126840; loss 0.002912; steps 219\n",
            "episode 10529; score:  1; q 0.127100; loss 0.001807; steps 181\n",
            "episode 10810; score:  3; q 0.124312; loss 0.002656; steps 281\n",
            "episode 11014; score:  2; q 0.128514; loss 0.002894; steps 204\n",
            "episode 11148; score:  0; q 0.123639; loss 0.002438; steps 134\n",
            "episode 11312; score:  1; q 0.128711; loss 0.003030; steps 164\n",
            "episode 11501; score:  1; q 0.123925; loss 0.002797; steps 189\n",
            "episode 11722; score:  2; q 0.127672; loss 0.002883; steps 221\n",
            "episode 11881; score:  1; q 0.126705; loss 0.003321; steps 159\n",
            "episode 12024; score:  0; q 0.125847; loss 0.002396; steps 143\n",
            "episode 12195; score:  1; q 0.126525; loss 0.002999; steps 171\n",
            "episode 12330; score:  0; q 0.126629; loss 0.002648; steps 135\n",
            "episode 12652; score:  5; q 0.130023; loss 0.002894; steps 322\n",
            "episode 12775; score:  0; q 0.122237; loss 0.003028; steps 123\n",
            "episode 13014; score:  3; q 0.129440; loss 0.003055; steps 239\n",
            "episode 13161; score:  0; q 0.126287; loss 0.003382; steps 147\n",
            "episode 13345; score:  1; q 0.123745; loss 0.003208; steps 184\n",
            "episode 13473; score:  0; q 0.126037; loss 0.002432; steps 128\n",
            "episode 13671; score:  2; q 0.139996; loss 0.003138; steps 198\n",
            "episode 13976; score:  4; q 0.142520; loss 0.002600; steps 305\n",
            "episode 14276; score:  4; q 0.125867; loss 0.002902; steps 300\n",
            "episode 14435; score:  1; q 0.131970; loss 0.003126; steps 159\n",
            "episode 14592; score:  1; q 0.131109; loss 0.002578; steps 157\n",
            "episode 14801; score:  2; q 0.128433; loss 0.003786; steps 209\n",
            "episode 14940; score:  0; q 0.126423; loss 0.002686; steps 139\n",
            "episode 15068; score:  0; q 0.125388; loss 0.003277; steps 128\n",
            "episode 15246; score:  1; q 0.123658; loss 0.003314; steps 178\n",
            "episode 15380; score:  0; q 0.123547; loss 0.002668; steps 134\n",
            "episode 15553; score:  1; q 0.124531; loss 0.002608; steps 173\n",
            "episode 15848; score:  4; q 0.122151; loss 0.002636; steps 295\n",
            "episode 16060; score:  2; q 0.127940; loss 0.003370; steps 212\n",
            "episode 16261; score:  2; q 0.127834; loss 0.002782; steps 201\n",
            "episode 16497; score:  3; q 0.127227; loss 0.003748; steps 236\n",
            "episode 16633; score:  0; q 0.129743; loss 0.003198; steps 136\n",
            "episode 16767; score:  0; q 0.128971; loss 0.003360; steps 134\n",
            "episode 16927; score:  1; q 0.131363; loss 0.003494; steps 160\n",
            "episode 17118; score:  2; q 0.133618; loss 0.003333; steps 191\n",
            "episode 17342; score:  3; q 0.129596; loss 0.002707; steps 224\n",
            "episode 17546; score:  2; q 0.133089; loss 0.003578; steps 204\n",
            "episode 17708; score:  1; q 0.128164; loss 0.002783; steps 162\n",
            "episode 17887; score:  1; q 0.125669; loss 0.003037; steps 179\n",
            "episode 18175; score:  4; q 0.133634; loss 0.003769; steps 288\n",
            "episode 18377; score:  2; q 0.142557; loss 0.003305; steps 202\n",
            "episode 18557; score:  1; q 0.128533; loss 0.002507; steps 180\n",
            "episode 18775; score:  2; q 0.125646; loss 0.003350; steps 218\n",
            "episode 18984; score:  2; q 0.128500; loss 0.003341; steps 209\n",
            "episode 19116; score:  0; q 0.127598; loss 0.003180; steps 132\n",
            "episode 19322; score:  2; q 0.133632; loss 0.003092; steps 206\n",
            "episode 19444; score:  0; q 0.127317; loss 0.003311; steps 122\n",
            "episode 19578; score:  0; q 0.126919; loss 0.002210; steps 134\n",
            "episode 19781; score:  2; q 0.113609; loss 0.002910; steps 203\n",
            "episode 19955; score:  1; q 0.126465; loss 0.003036; steps 174\n",
            "episode 20108; score:  1; q 0.129804; loss 0.002752; steps 153\n",
            "episode 20318; score:  2; q 0.136287; loss 0.003768; steps 210\n",
            "episode 20460; score:  0; q 0.134627; loss 0.003064; steps 142\n",
            "episode 20592; score:  0; q 0.131644; loss 0.002943; steps 132\n",
            "episode 20810; score:  2; q 0.135883; loss 0.003633; steps 218\n",
            "episode 20973; score:  1; q 0.134084; loss 0.002862; steps 163\n",
            "episode 21099; score:  0; q 0.130228; loss 0.003692; steps 126\n",
            "episode 21324; score:  2; q 0.133701; loss 0.003382; steps 225\n",
            "episode 21537; score:  2; q 0.138146; loss 0.004941; steps 213\n",
            "episode 21767; score:  2; q 0.131351; loss 0.003777; steps 230\n",
            "episode 21897; score:  0; q 0.134079; loss 0.003463; steps 130\n",
            "episode 22104; score:  2; q 0.132477; loss 0.004046; steps 207\n",
            "episode 22290; score:  1; q 0.133128; loss 0.003424; steps 186\n",
            "episode 22420; score:  0; q 0.132555; loss 0.003464; steps 130\n",
            "episode 22553; score:  0; q 0.133632; loss 0.003040; steps 133\n",
            "episode 22811; score:  3; q 0.133465; loss 0.003668; steps 258\n",
            "episode 23031; score:  2; q 0.131481; loss 0.003599; steps 220\n",
            "episode 23291; score:  3; q 0.134149; loss 0.002810; steps 260\n",
            "episode 23423; score:  0; q 0.133442; loss 0.003648; steps 132\n",
            "episode 23555; score:  0; q 0.133753; loss 0.003760; steps 132\n",
            "episode 23821; score:  4; q 0.146039; loss 0.004022; steps 266\n",
            "episode 23958; score:  0; q 0.131647; loss 0.003513; steps 137\n",
            "episode 24275; score:  5; q 0.128392; loss 0.003039; steps 317\n",
            "episode 24466; score:  2; q 0.131917; loss 0.002849; steps 191\n",
            "episode 24642; score:  1; q 0.131947; loss 0.003089; steps 176\n",
            "episode 24777; score:  0; q 0.131075; loss 0.002995; steps 135\n",
            "episode 24956; score:  1; q 0.133130; loss 0.003727; steps 179\n",
            "episode 25086; score:  0; q 0.130362; loss 0.003108; steps 130\n",
            "episode 25398; score:  4; q 0.128090; loss 0.003827; steps 312\n",
            "episode 25555; score:  1; q 0.145177; loss 0.004150; steps 157\n",
            "episode 25756; score:  2; q 0.127473; loss 0.002787; steps 201\n",
            "episode 25892; score:  0; q 0.132777; loss 0.002631; steps 136\n",
            "episode 26069; score:  1; q 0.136227; loss 0.003070; steps 177\n",
            "episode 26194; score:  0; q 0.132451; loss 0.003110; steps 125\n",
            "episode 26330; score:  0; q 0.131974; loss 0.002290; steps 136\n",
            "episode 26463; score:  0; q 0.132769; loss 0.003845; steps 133\n",
            "episode 26617; score:  1; q 0.136471; loss 0.003631; steps 154\n",
            "episode 26748; score:  0; q 0.134183; loss 0.003791; steps 131\n",
            "episode 26923; score:  1; q 0.134323; loss 0.003372; steps 175\n",
            "episode 27050; score:  0; q 0.130690; loss 0.004031; steps 127\n",
            "episode 27213; score:  1; q 0.136110; loss 0.003996; steps 163\n",
            "episode 27537; score:  5; q 0.142364; loss 0.002973; steps 324\n",
            "episode 27712; score:  1; q 0.134466; loss 0.002931; steps 175\n",
            "episode 27923; score:  2; q 0.136786; loss 0.002800; steps 211\n",
            "episode 28134; score:  2; q 0.135445; loss 0.003457; steps 211\n",
            "episode 28338; score:  2; q 0.134016; loss 0.003878; steps 204\n",
            "episode 28474; score:  0; q 0.132757; loss 0.003651; steps 136\n",
            "episode 28608; score:  0; q 0.131038; loss 0.003360; steps 134\n",
            "episode 28792; score:  1; q 0.130934; loss 0.004046; steps 184\n",
            "episode 29024; score:  3; q 0.143017; loss 0.002683; steps 232\n",
            "episode 29157; score:  0; q 0.132197; loss 0.002689; steps 133\n",
            "episode 29312; score:  1; q 0.132194; loss 0.003107; steps 155\n",
            "episode 29481; score:  1; q 0.133687; loss 0.003947; steps 169\n",
            "episode 29613; score:  0; q 0.131974; loss 0.002359; steps 132\n",
            "episode 29826; score:  2; q 0.135592; loss 0.003063; steps 213\n",
            "episode 30070; score:  3; q 0.138089; loss 0.003126; steps 244\n",
            "episode 30320; score:  4; q 0.138749; loss 0.003355; steps 250\n",
            "episode 30444; score:  0; q 0.135621; loss 0.002135; steps 124\n",
            "episode 30669; score:  2; q 0.136408; loss 0.003862; steps 225\n",
            "episode 30932; score:  3; q 0.146276; loss 0.003424; steps 263\n",
            "episode 31057; score:  0; q 0.137939; loss 0.003107; steps 125\n",
            "episode 31260; score:  2; q 0.140316; loss 0.003670; steps 203\n",
            "episode 31402; score:  0; q 0.135180; loss 0.002846; steps 142\n",
            "episode 31558; score:  1; q 0.140681; loss 0.004175; steps 156\n",
            "episode 31755; score:  2; q 0.139722; loss 0.003703; steps 197\n",
            "episode 31887; score:  0; q 0.137754; loss 0.003177; steps 132\n",
            "episode 32026; score:  0; q 0.134961; loss 0.003463; steps 139\n",
            "episode 32177; score:  1; q 0.136546; loss 0.003597; steps 151\n",
            "episode 32449; score:  3; q 0.134820; loss 0.003084; steps 272\n",
            "episode 32610; score:  1; q 0.135520; loss 0.003089; steps 161\n",
            "episode 32903; score:  4; q 0.134082; loss 0.003233; steps 293\n",
            "episode 33068; score:  1; q 0.139439; loss 0.003202; steps 165\n",
            "episode 33297; score:  3; q 0.142880; loss 0.003996; steps 229\n",
            "episode 33431; score:  0; q 0.134962; loss 0.002670; steps 134\n",
            "episode 33566; score:  0; q 0.136355; loss 0.003564; steps 135\n",
            "episode 33772; score:  2; q 0.148508; loss 0.003841; steps 206\n",
            "episode 34038; score:  3; q 0.135318; loss 0.003386; steps 266\n",
            "episode 34163; score:  0; q 0.133181; loss 0.003848; steps 125\n",
            "episode 34346; score:  2; q 0.134435; loss 0.003478; steps 183\n",
            "episode 34474; score:  0; q 0.136917; loss 0.002792; steps 128\n",
            "episode 34610; score:  0; q 0.138198; loss 0.002858; steps 136\n",
            "episode 34767; score:  1; q 0.140613; loss 0.003756; steps 157\n",
            "episode 34923; score:  1; q 0.132403; loss 0.003780; steps 156\n",
            "episode 35105; score:  1; q 0.136455; loss 0.004676; steps 182\n",
            "episode 35278; score:  1; q 0.137510; loss 0.003592; steps 173\n",
            "episode 35532; score:  3; q 0.140380; loss 0.003301; steps 254\n",
            "episode 35710; score:  1; q 0.132610; loss 0.003055; steps 178\n",
            "episode 35838; score:  0; q 0.138533; loss 0.004240; steps 128\n",
            "episode 36092; score:  3; q 0.146409; loss 0.002878; steps 254\n",
            "episode 36225; score:  0; q 0.137013; loss 0.003964; steps 133\n",
            "episode 36431; score:  2; q 0.139834; loss 0.003243; steps 206\n",
            "episode 36616; score:  1; q 0.135445; loss 0.003608; steps 185\n",
            "episode 36823; score:  2; q 0.140160; loss 0.003748; steps 207\n",
            "episode 37050; score:  3; q 0.146701; loss 0.004030; steps 227\n",
            "episode 37311; score:  3; q 0.147867; loss 0.003627; steps 261\n",
            "episode 37562; score:  3; q 0.140554; loss 0.003402; steps 251\n",
            "episode 37697; score:  0; q 0.137598; loss 0.003450; steps 135\n",
            "episode 37820; score:  0; q 0.134661; loss 0.003783; steps 123\n",
            "episode 37975; score:  1; q 0.136577; loss 0.003207; steps 155\n",
            "episode 38103; score:  0; q 0.134719; loss 0.004001; steps 128\n",
            "episode 38291; score:  1; q 0.134459; loss 0.003633; steps 188\n",
            "episode 38446; score:  1; q 0.138098; loss 0.002809; steps 155\n",
            "episode 38646; score:  2; q 0.139572; loss 0.003647; steps 200\n",
            "episode 38818; score:  1; q 0.138958; loss 0.003071; steps 172\n",
            "episode 39030; score:  2; q 0.139851; loss 0.003733; steps 212\n",
            "episode 39208; score:  1; q 0.143029; loss 0.002448; steps 178\n",
            "episode 39395; score:  1; q 0.137823; loss 0.002908; steps 187\n",
            "episode 39603; score:  2; q 0.133941; loss 0.003435; steps 208\n",
            "episode 39751; score:  0; q 0.135936; loss 0.002938; steps 148\n",
            "episode 39876; score:  0; q 0.138193; loss 0.003232; steps 125\n",
            "episode 40051; score:  1; q 0.136220; loss 0.003466; steps 175\n",
            "episode 40281; score:  3; q 0.151718; loss 0.003309; steps 230\n",
            "episode 40411; score:  0; q 0.140359; loss 0.003941; steps 130\n",
            "episode 40620; score:  2; q 0.150223; loss 0.003786; steps 209\n",
            "episode 40754; score:  0; q 0.142232; loss 0.003707; steps 134\n",
            "episode 40902; score:  0; q 0.142962; loss 0.003045; steps 148\n",
            "episode 41123; score:  2; q 0.146348; loss 0.003790; steps 221\n",
            "episode 41245; score:  0; q 0.142383; loss 0.003691; steps 122\n",
            "episode 41438; score:  2; q 0.152074; loss 0.003218; steps 193\n",
            "episode 41591; score:  1; q 0.146492; loss 0.003552; steps 153\n",
            "episode 41766; score:  1; q 0.143841; loss 0.003810; steps 175\n",
            "episode 41921; score:  1; q 0.142427; loss 0.003803; steps 155\n",
            "episode 42145; score:  3; q 0.152079; loss 0.004082; steps 224\n",
            "episode 42282; score:  0; q 0.143590; loss 0.002389; steps 137\n",
            "episode 42458; score:  1; q 0.142706; loss 0.002475; steps 176\n",
            "episode 42591; score:  0; q 0.142125; loss 0.003152; steps 133\n",
            "episode 42757; score:  1; q 0.142363; loss 0.003183; steps 166\n",
            "episode 42983; score:  2; q 0.137186; loss 0.004524; steps 226\n",
            "episode 43109; score:  0; q 0.143516; loss 0.004671; steps 126\n",
            "episode 43263; score:  1; q 0.148261; loss 0.003426; steps 154\n",
            "episode 43400; score:  0; q 0.143880; loss 0.003063; steps 137\n",
            "episode 43657; score:  3; q 0.146755; loss 0.003622; steps 257\n",
            "episode 43782; score:  0; q 0.139622; loss 0.004583; steps 125\n",
            "episode 43908; score:  0; q 0.140673; loss 0.002718; steps 126\n",
            "episode 44037; score:  0; q 0.140974; loss 0.002413; steps 129\n",
            "episode 44199; score:  1; q 0.147441; loss 0.004116; steps 162\n",
            "episode 44381; score:  1; q 0.142269; loss 0.004089; steps 182\n",
            "episode 44581; score:  2; q 0.156080; loss 0.004108; steps 200\n",
            "episode 44735; score:  1; q 0.145428; loss 0.002828; steps 154\n",
            "episode 44939; score:  2; q 0.151236; loss 0.003348; steps 204\n",
            "episode 45151; score:  2; q 0.142249; loss 0.003516; steps 212\n",
            "episode 45327; score:  1; q 0.141716; loss 0.003002; steps 176\n",
            "episode 45675; score:  6; q 0.150591; loss 0.004056; steps 348\n",
            "episode 45807; score:  0; q 0.146026; loss 0.003878; steps 132\n",
            "episode 46014; score:  2; q 0.145194; loss 0.003079; steps 207\n",
            "episode 46153; score:  0; q 0.143886; loss 0.004126; steps 139\n",
            "episode 46280; score:  0; q 0.143410; loss 0.002332; steps 127\n",
            "episode 46459; score:  1; q 0.143378; loss 0.003641; steps 179\n",
            "episode 46632; score:  1; q 0.147240; loss 0.004032; steps 173\n",
            "episode 46767; score:  0; q 0.146930; loss 0.003905; steps 135\n",
            "episode 46972; score:  2; q 0.149683; loss 0.002882; steps 205\n",
            "episode 47123; score:  1; q 0.145809; loss 0.003801; steps 151\n",
            "episode 47304; score:  1; q 0.146150; loss 0.002921; steps 181\n",
            "episode 47440; score:  0; q 0.144347; loss 0.004107; steps 136\n",
            "episode 47583; score:  0; q 0.143473; loss 0.003367; steps 143\n",
            "episode 47810; score:  2; q 0.145223; loss 0.003827; steps 227\n",
            "episode 48063; score:  3; q 0.142891; loss 0.003863; steps 253\n",
            "episode 48240; score:  1; q 0.145312; loss 0.003421; steps 177\n",
            "episode 48372; score:  0; q 0.142147; loss 0.003527; steps 132\n",
            "episode 48508; score:  0; q 0.143436; loss 0.002745; steps 136\n",
            "episode 48649; score:  0; q 0.142485; loss 0.002976; steps 141\n",
            "episode 48784; score:  0; q 0.143130; loss 0.003108; steps 135\n",
            "episode 48943; score:  1; q 0.146571; loss 0.004485; steps 159\n",
            "episode 49194; score:  3; q 0.142271; loss 0.003953; steps 251\n",
            "episode 49424; score:  2; q 0.141275; loss 0.002839; steps 230\n",
            "episode 49560; score:  0; q 0.141070; loss 0.005007; steps 136\n",
            "episode 49719; score:  1; q 0.146885; loss 0.004099; steps 159\n",
            "episode 49898; score:  1; q 0.135142; loss 0.002435; steps 179\n",
            "episode 50079; score:  1; q 0.143876; loss 0.003785; steps 181\n",
            "episode 50247; score:  1; q 0.147208; loss 0.003877; steps 168\n",
            "episode 50378; score:  0; q 0.148847; loss 0.002732; steps 131\n",
            "episode 50504; score:  0; q 0.145455; loss 0.002961; steps 126\n",
            "episode 50659; score:  1; q 0.146995; loss 0.003902; steps 155\n",
            "episode 50790; score:  0; q 0.146822; loss 0.003672; steps 131\n",
            "episode 50965; score:  1; q 0.145868; loss 0.004165; steps 175\n",
            "episode 51165; score:  2; q 0.154623; loss 0.003417; steps 200\n",
            "episode 51363; score:  2; q 0.160998; loss 0.003528; steps 198\n",
            "episode 51540; score:  1; q 0.149926; loss 0.002811; steps 177\n",
            "episode 51694; score:  1; q 0.150477; loss 0.002726; steps 154\n",
            "episode 51935; score:  3; q 0.157575; loss 0.003926; steps 241\n",
            "episode 52138; score:  2; q 0.148883; loss 0.002985; steps 203\n",
            "episode 52317; score:  1; q 0.150963; loss 0.003640; steps 179\n",
            "episode 52508; score:  1; q 0.149217; loss 0.003897; steps 191\n",
            "episode 52661; score:  1; q 0.147062; loss 0.003851; steps 153\n",
            "episode 52844; score:  2; q 0.152273; loss 0.003393; steps 183\n",
            "episode 53017; score:  1; q 0.146346; loss 0.003411; steps 173\n",
            "episode 53168; score:  1; q 0.147754; loss 0.003496; steps 151\n",
            "episode 53380; score:  2; q 0.146775; loss 0.003660; steps 212\n",
            "episode 53513; score:  0; q 0.149748; loss 0.003270; steps 133\n",
            "episode 53642; score:  0; q 0.149767; loss 0.003131; steps 129\n",
            "episode 53849; score:  2; q 0.157341; loss 0.003522; steps 207\n",
            "episode 54056; score:  2; q 0.153252; loss 0.003154; steps 207\n",
            "episode 54181; score:  0; q 0.147151; loss 0.002861; steps 125\n",
            "episode 54365; score:  1; q 0.148588; loss 0.002704; steps 184\n",
            "episode 54615; score:  3; q 0.144258; loss 0.004032; steps 250\n",
            "episode 54819; score:  2; q 0.150244; loss 0.003803; steps 204\n",
            "episode 55013; score:  2; q 0.156345; loss 0.003281; steps 194\n",
            "episode 55251; score:  3; q 0.142161; loss 0.003846; steps 238\n",
            "episode 55414; score:  1; q 0.148753; loss 0.002768; steps 163\n",
            "episode 55618; score:  2; q 0.151039; loss 0.004933; steps 204\n",
            "episode 55896; score:  3; q 0.147537; loss 0.004238; steps 278\n",
            "episode 56054; score:  1; q 0.148538; loss 0.002854; steps 158\n",
            "episode 56176; score:  0; q 0.145712; loss 0.003055; steps 122\n",
            "episode 56303; score:  0; q 0.148018; loss 0.003910; steps 127\n",
            "episode 56511; score:  2; q 0.154677; loss 0.003508; steps 208\n",
            "episode 56747; score:  3; q 0.150130; loss 0.003553; steps 236\n",
            "episode 56963; score:  2; q 0.155022; loss 0.003736; steps 216\n",
            "episode 57180; score:  2; q 0.149261; loss 0.003009; steps 217\n",
            "episode 57307; score:  0; q 0.145875; loss 0.003425; steps 127\n",
            "episode 57530; score:  2; q 0.147276; loss 0.002650; steps 223\n",
            "episode 57665; score:  0; q 0.148435; loss 0.002764; steps 135\n",
            "episode 57787; score:  0; q 0.145742; loss 0.003942; steps 122\n",
            "episode 57914; score:  0; q 0.147452; loss 0.002939; steps 127\n",
            "episode 58117; score:  2; q 0.159690; loss 0.003366; steps 203\n",
            "episode 58282; score:  1; q 0.147927; loss 0.002920; steps 165\n",
            "episode 58451; score:  1; q 0.153424; loss 0.003309; steps 169\n",
            "episode 58610; score:  1; q 0.151289; loss 0.002252; steps 159\n",
            "episode 58885; score:  3; q 0.147615; loss 0.003162; steps 275\n",
            "episode 59116; score:  3; q 0.149230; loss 0.003629; steps 231\n",
            "episode 59309; score:  2; q 0.146633; loss 0.003617; steps 193\n",
            "episode 59479; score:  1; q 0.149877; loss 0.003470; steps 170\n",
            "episode 59604; score:  0; q 0.148119; loss 0.003477; steps 125\n",
            "episode 59734; score:  0; q 0.147706; loss 0.002871; steps 130\n",
            "episode 59936; score:  2; q 0.159290; loss 0.003459; steps 202\n",
            "episode 60102; score:  1; q 0.153027; loss 0.003280; steps 166\n",
            "episode 60332; score:  2; q 0.148596; loss 0.003576; steps 230\n",
            "episode 60510; score:  1; q 0.151739; loss 0.004526; steps 178\n",
            "episode 60763; score:  3; q 0.154735; loss 0.003073; steps 253\n",
            "episode 60949; score:  1; q 0.151331; loss 0.002759; steps 186\n",
            "episode 61152; score:  2; q 0.159798; loss 0.003595; steps 203\n",
            "episode 61313; score:  1; q 0.153501; loss 0.002705; steps 161\n",
            "episode 61479; score:  1; q 0.156177; loss 0.003647; steps 166\n",
            "episode 61753; score:  3; q 0.148437; loss 0.003849; steps 274\n",
            "episode 61960; score:  2; q 0.155443; loss 0.003078; steps 207\n",
            "episode 62087; score:  0; q 0.154047; loss 0.003909; steps 127\n",
            "episode 62216; score:  0; q 0.157265; loss 0.003967; steps 129\n",
            "episode 62547; score:  4; q 0.149970; loss 0.003145; steps 331\n",
            "episode 62683; score:  0; q 0.153067; loss 0.002744; steps 136\n",
            "episode 62862; score:  2; q 0.155480; loss 0.003556; steps 179\n",
            "episode 63098; score:  3; q 0.152147; loss 0.004204; steps 236\n",
            "episode 63273; score:  1; q 0.160593; loss 0.004427; steps 175\n",
            "episode 63428; score:  1; q 0.156579; loss 0.003705; steps 155\n",
            "episode 63558; score:  0; q 0.155349; loss 0.002154; steps 130\n",
            "episode 63736; score:  1; q 0.156679; loss 0.003663; steps 178\n",
            "episode 63939; score:  2; q 0.157260; loss 0.003290; steps 203\n",
            "episode 64073; score:  0; q 0.155452; loss 0.003247; steps 134\n",
            "episode 64206; score:  0; q 0.156364; loss 0.004543; steps 133\n",
            "episode 64341; score:  0; q 0.154919; loss 0.003452; steps 135\n",
            "episode 64591; score:  3; q 0.160332; loss 0.003169; steps 250\n",
            "episode 64726; score:  0; q 0.154713; loss 0.004250; steps 135\n",
            "episode 64861; score:  0; q 0.153434; loss 0.002650; steps 135\n",
            "episode 65035; score:  1; q 0.149937; loss 0.003126; steps 174\n",
            "episode 65216; score:  1; q 0.153979; loss 0.003432; steps 181\n",
            "episode 65394; score:  1; q 0.154219; loss 0.003575; steps 178\n",
            "episode 65574; score:  1; q 0.165403; loss 0.004988; steps 180\n",
            "episode 65745; score:  1; q 0.156905; loss 0.002187; steps 171\n",
            "episode 66013; score:  3; q 0.151156; loss 0.003592; steps 268\n",
            "episode 66264; score:  3; q 0.159302; loss 0.003341; steps 251\n",
            "episode 66463; score:  2; q 0.164508; loss 0.003357; steps 199\n",
            "episode 66622; score:  1; q 0.156195; loss 0.003807; steps 159\n",
            "episode 66866; score:  3; q 0.161818; loss 0.003627; steps 244\n",
            "episode 67069; score:  2; q 0.166091; loss 0.003593; steps 203\n",
            "episode 67269; score:  2; q 0.166320; loss 0.003413; steps 200\n",
            "episode 67401; score:  0; q 0.150737; loss 0.003416; steps 132\n",
            "episode 67635; score:  3; q 0.162668; loss 0.003712; steps 234\n",
            "episode 67813; score:  1; q 0.155617; loss 0.004182; steps 178\n",
            "episode 67976; score:  1; q 0.160761; loss 0.003992; steps 163\n",
            "episode 68181; score:  2; q 0.167142; loss 0.002506; steps 205\n",
            "episode 68317; score:  0; q 0.153111; loss 0.003086; steps 136\n",
            "episode 68605; score:  4; q 0.166953; loss 0.003771; steps 288\n",
            "episode 68810; score:  2; q 0.157814; loss 0.002958; steps 205\n",
            "episode 68954; score:  0; q 0.153981; loss 0.003130; steps 144\n",
            "episode 69115; score:  1; q 0.156915; loss 0.003184; steps 161\n",
            "episode 69350; score:  3; q 0.162388; loss 0.003369; steps 235\n",
            "episode 69536; score:  1; q 0.151575; loss 0.003587; steps 186\n",
            "episode 69714; score:  1; q 0.154777; loss 0.003836; steps 178\n",
            "episode 69847; score:  0; q 0.152882; loss 0.002225; steps 133\n",
            "episode 69972; score:  0; q 0.151417; loss 0.003848; steps 125\n",
            "episode 70222; score:  3; q 0.155926; loss 0.002991; steps 250\n",
            "episode 70431; score:  2; q 0.164936; loss 0.003565; steps 209\n",
            "episode 70557; score:  0; q 0.161257; loss 0.003693; steps 126\n",
            "episode 70686; score:  0; q 0.160859; loss 0.002055; steps 129\n",
            "episode 70847; score:  1; q 0.160500; loss 0.002417; steps 161\n",
            "episode 71027; score:  1; q 0.166699; loss 0.003532; steps 180\n",
            "episode 71192; score:  1; q 0.165890; loss 0.003668; steps 165\n",
            "episode 71376; score:  1; q 0.160797; loss 0.003794; steps 184\n",
            "episode 71535; score:  1; q 0.164076; loss 0.002545; steps 159\n",
            "episode 71760; score:  2; q 0.161478; loss 0.002558; steps 225\n",
            "episode 71933; score:  1; q 0.160689; loss 0.002428; steps 173\n",
            "episode 72156; score:  2; q 0.162288; loss 0.003411; steps 223\n",
            "episode 72329; score:  1; q 0.166578; loss 0.003856; steps 173\n",
            "episode 72538; score:  2; q 0.159757; loss 0.002381; steps 209\n",
            "episode 72697; score:  1; q 0.162990; loss 0.004100; steps 159\n",
            "episode 72830; score:  0; q 0.163298; loss 0.003734; steps 133\n",
            "episode 72968; score:  0; q 0.161535; loss 0.003934; steps 138\n",
            "episode 73100; score:  0; q 0.160004; loss 0.002711; steps 132\n",
            "episode 73234; score:  0; q 0.157847; loss 0.003361; steps 134\n",
            "episode 73427; score:  2; q 0.159821; loss 0.004176; steps 193\n",
            "episode 73582; score:  1; q 0.163427; loss 0.003307; steps 155\n",
            "episode 73862; score:  4; q 0.155268; loss 0.003383; steps 280\n",
            "episode 74042; score:  1; q 0.164070; loss 0.003278; steps 180\n",
            "episode 74206; score:  1; q 0.166175; loss 0.003220; steps 164\n",
            "episode 74458; score:  3; q 0.165398; loss 0.003511; steps 252\n",
            "episode 74739; score:  3; q 0.160268; loss 0.003700; steps 281\n",
            "episode 74898; score:  1; q 0.160938; loss 0.003611; steps 159\n",
            "episode 75123; score:  2; q 0.161754; loss 0.003861; steps 225\n",
            "episode 75299; score:  1; q 0.160760; loss 0.003529; steps 176\n",
            "episode 75573; score:  3; q 0.159738; loss 0.003568; steps 274\n",
            "episode 75800; score:  2; q 0.170288; loss 0.003013; steps 227\n",
            "episode 75938; score:  0; q 0.159470; loss 0.003153; steps 138\n",
            "episode 76111; score:  1; q 0.162369; loss 0.002875; steps 173\n",
            "episode 76290; score:  1; q 0.160007; loss 0.003990; steps 179\n",
            "episode 76450; score:  1; q 0.157971; loss 0.003589; steps 160\n",
            "episode 76634; score:  1; q 0.158251; loss 0.002537; steps 184\n",
            "episode 76759; score:  0; q 0.157238; loss 0.002366; steps 125\n",
            "episode 76891; score:  0; q 0.160004; loss 0.004696; steps 132\n",
            "episode 77106; score:  2; q 0.166693; loss 0.003179; steps 215\n",
            "episode 77316; score:  2; q 0.163863; loss 0.003694; steps 210\n",
            "episode 77444; score:  0; q 0.158679; loss 0.003274; steps 128\n",
            "episode 77636; score:  2; q 0.161384; loss 0.003719; steps 192\n",
            "episode 77767; score:  0; q 0.161410; loss 0.002730; steps 131\n",
            "episode 77967; score:  2; q 0.169855; loss 0.003568; steps 200\n",
            "episode 78179; score:  2; q 0.165699; loss 0.003878; steps 212\n",
            "episode 78346; score:  1; q 0.164191; loss 0.003716; steps 167\n",
            "episode 78561; score:  2; q 0.161272; loss 0.003538; steps 215\n",
            "episode 78800; score:  2; q 0.156114; loss 0.002991; steps 239\n",
            "episode 79002; score:  2; q 0.164486; loss 0.002539; steps 202\n",
            "episode 79228; score:  2; q 0.160054; loss 0.003026; steps 226\n",
            "episode 79440; score:  2; q 0.169114; loss 0.004096; steps 212\n",
            "episode 79643; score:  2; q 0.163000; loss 0.003063; steps 203\n",
            "episode 79777; score:  0; q 0.160327; loss 0.002900; steps 134\n",
            "episode 79916; score:  0; q 0.163194; loss 0.002797; steps 139\n",
            "episode 80056; score:  0; q 0.165025; loss 0.004332; steps 140\n",
            "episode 80190; score:  0; q 0.169175; loss 0.004511; steps 134\n",
            "episode 80319; score:  0; q 0.168171; loss 0.003732; steps 129\n",
            "episode 80566; score:  3; q 0.173770; loss 0.002832; steps 247\n",
            "episode 80781; score:  2; q 0.170192; loss 0.004041; steps 215\n",
            "episode 80995; score:  3; q 0.172048; loss 0.003914; steps 214\n",
            "episode 81183; score:  2; q 0.154145; loss 0.003307; steps 188\n",
            "episode 81355; score:  1; q 0.172520; loss 0.003789; steps 172\n",
            "episode 81642; score:  4; q 0.183542; loss 0.003516; steps 287\n",
            "episode 81773; score:  0; q 0.171693; loss 0.003203; steps 131\n",
            "episode 82020; score:  3; q 0.160007; loss 0.003890; steps 247\n",
            "episode 82228; score:  2; q 0.170900; loss 0.002690; steps 208\n",
            "episode 82384; score:  1; q 0.170913; loss 0.003882; steps 156\n",
            "episode 82538; score:  1; q 0.162930; loss 0.002925; steps 154\n",
            "episode 82719; score:  1; q 0.165327; loss 0.003773; steps 181\n",
            "episode 82900; score:  1; q 0.169658; loss 0.003773; steps 181\n",
            "episode 83087; score:  2; q 0.172430; loss 0.002577; steps 187\n",
            "episode 83291; score:  2; q 0.180472; loss 0.003350; steps 204\n",
            "episode 83424; score:  0; q 0.172058; loss 0.004313; steps 133\n",
            "episode 83722; score:  4; q 0.165218; loss 0.003077; steps 298\n",
            "episode 83859; score:  0; q 0.170992; loss 0.003739; steps 137\n",
            "episode 84012; score:  0; q 0.170423; loss 0.003451; steps 153\n",
            "episode 84149; score:  0; q 0.170838; loss 0.002950; steps 137\n",
            "episode 84388; score:  2; q 0.166342; loss 0.003443; steps 239\n",
            "episode 84527; score:  0; q 0.170590; loss 0.004241; steps 139\n",
            "episode 84661; score:  0; q 0.170422; loss 0.003476; steps 134\n",
            "episode 84929; score:  3; q 0.170762; loss 0.003246; steps 268\n",
            "episode 85082; score:  0; q 0.170076; loss 0.003047; steps 153\n",
            "episode 85212; score:  0; q 0.166047; loss 0.002870; steps 130\n",
            "episode 85374; score:  1; q 0.169326; loss 0.004210; steps 162\n",
            "episode 85505; score:  0; q 0.171421; loss 0.002851; steps 131\n",
            "episode 85821; score:  4; q 0.170210; loss 0.003927; steps 316\n",
            "episode 86049; score:  3; q 0.163848; loss 0.003608; steps 228\n",
            "episode 86232; score:  1; q 0.168946; loss 0.003479; steps 183\n",
            "episode 86464; score:  3; q 0.177147; loss 0.003545; steps 232\n",
            "episode 86590; score:  0; q 0.170841; loss 0.004065; steps 126\n",
            "episode 86796; score:  2; q 0.178302; loss 0.002117; steps 206\n",
            "episode 87112; score:  5; q 0.170837; loss 0.003342; steps 316\n",
            "episode 87242; score:  0; q 0.170186; loss 0.003701; steps 130\n",
            "episode 87417; score:  1; q 0.171005; loss 0.002843; steps 175\n",
            "episode 87548; score:  0; q 0.172444; loss 0.003316; steps 131\n",
            "episode 87747; score:  2; q 0.176319; loss 0.003432; steps 199\n",
            "episode 87877; score:  0; q 0.174206; loss 0.004052; steps 130\n",
            "episode 88044; score:  1; q 0.172991; loss 0.003903; steps 167\n",
            "episode 88216; score:  1; q 0.173108; loss 0.003430; steps 172\n",
            "episode 88444; score:  2; q 0.173528; loss 0.003201; steps 228\n",
            "episode 88601; score:  1; q 0.169408; loss 0.004050; steps 157\n",
            "episode 88859; score:  3; q 0.172198; loss 0.003729; steps 258\n",
            "episode 89012; score:  1; q 0.171311; loss 0.004355; steps 153\n",
            "episode 89219; score:  2; q 0.180199; loss 0.004268; steps 207\n",
            "episode 89374; score:  1; q 0.168864; loss 0.004399; steps 155\n",
            "episode 89508; score:  0; q 0.171696; loss 0.002903; steps 134\n",
            "episode 89877; score:  5; q 0.164780; loss 0.002905; steps 369\n",
            "episode 90084; score:  2; q 0.168972; loss 0.003757; steps 207\n",
            "episode 90293; score:  2; q 0.180848; loss 0.004228; steps 209\n",
            "episode 90472; score:  1; q 0.173872; loss 0.003815; steps 179\n",
            "episode 90624; score:  1; q 0.175933; loss 0.002457; steps 152\n",
            "episode 90755; score:  0; q 0.176427; loss 0.003201; steps 131\n",
            "episode 90899; score:  0; q 0.176047; loss 0.002700; steps 144\n",
            "episode 91204; score:  4; q 0.180802; loss 0.003764; steps 305\n",
            "episode 91428; score:  2; q 0.176435; loss 0.002916; steps 224\n",
            "episode 91600; score:  1; q 0.174071; loss 0.003071; steps 172\n",
            "episode 91776; score:  1; q 0.174324; loss 0.002651; steps 176\n",
            "episode 91902; score:  0; q 0.172137; loss 0.003818; steps 126\n",
            "episode 92038; score:  0; q 0.177086; loss 0.002973; steps 136\n",
            "episode 92173; score:  0; q 0.174013; loss 0.004248; steps 135\n",
            "episode 92376; score:  2; q 0.187111; loss 0.003670; steps 203\n",
            "episode 92579; score:  2; q 0.174412; loss 0.003366; steps 203\n",
            "episode 92788; score:  2; q 0.174944; loss 0.003491; steps 209\n",
            "episode 92966; score:  1; q 0.175414; loss 0.003575; steps 178\n",
            "episode 93173; score:  2; q 0.180000; loss 0.003451; steps 207\n",
            "episode 93366; score:  2; q 0.180944; loss 0.003538; steps 193\n",
            "episode 93507; score:  0; q 0.175773; loss 0.003743; steps 141\n",
            "episode 93667; score:  1; q 0.180485; loss 0.003493; steps 160\n",
            "episode 93797; score:  0; q 0.174296; loss 0.002632; steps 130\n",
            "episode 93923; score:  0; q 0.175736; loss 0.003329; steps 126\n",
            "episode 94078; score:  1; q 0.174718; loss 0.004300; steps 155\n",
            "episode 94314; score:  2; q 0.171261; loss 0.003421; steps 236\n",
            "episode 94468; score:  1; q 0.178515; loss 0.004029; steps 154\n",
            "episode 94666; score:  2; q 0.188424; loss 0.003683; steps 198\n",
            "episode 94802; score:  0; q 0.176122; loss 0.002744; steps 136\n",
            "episode 94938; score:  0; q 0.178475; loss 0.003425; steps 136\n",
            "episode 95219; score:  4; q 0.176534; loss 0.003371; steps 281\n",
            "episode 95441; score:  2; q 0.173045; loss 0.003844; steps 222\n",
            "episode 95569; score:  0; q 0.174526; loss 0.003518; steps 128\n",
            "episode 95873; score:  4; q 0.174617; loss 0.003422; steps 304\n",
            "episode 96074; score:  2; q 0.186607; loss 0.003014; steps 201\n",
            "episode 96256; score:  1; q 0.175055; loss 0.004344; steps 182\n",
            "episode 96393; score:  0; q 0.176080; loss 0.003962; steps 137\n",
            "episode 96708; score:  5; q 0.181790; loss 0.003890; steps 315\n",
            "episode 96838; score:  0; q 0.177048; loss 0.004291; steps 130\n",
            "episode 97072; score:  3; q 0.189150; loss 0.003712; steps 234\n",
            "episode 97273; score:  2; q 0.182007; loss 0.003860; steps 201\n",
            "episode 97539; score:  4; q 0.181257; loss 0.003328; steps 266\n",
            "episode 97778; score:  2; q 0.173897; loss 0.003445; steps 239\n",
            "episode 97910; score:  0; q 0.174523; loss 0.002945; steps 132\n",
            "episode 98119; score:  2; q 0.175470; loss 0.004154; steps 209\n",
            "episode 98321; score:  2; q 0.189073; loss 0.003916; steps 202\n",
            "episode 98519; score:  2; q 0.180256; loss 0.003295; steps 198\n",
            "episode 98771; score:  3; q 0.176339; loss 0.002654; steps 252\n",
            "episode 98976; score:  2; q 0.176997; loss 0.004082; steps 205\n",
            "episode 99108; score:  0; q 0.174050; loss 0.003996; steps 132\n",
            "episode 99374; score:  3; q 0.179836; loss 0.004254; steps 266\n",
            "episode 99597; score:  2; q 0.175553; loss 0.003621; steps 223\n",
            "episode 99880; score:  4; q 0.184885; loss 0.003619; steps 283\n",
            "episode 100008; score:  0; q 0.175726; loss 0.004722; steps 128\n",
            "episode 100161; score:  1; q 0.178841; loss 0.003660; steps 153\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-7e97b4ffd867>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_steps\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mupdate_model_rate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-e8531640601a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m       \u001b[0mdead\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mtarget_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "KWpnq9rgDqsW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**When our algorithm scores well enough, we can stop training.**"
      ]
    },
    {
      "metadata": {
        "id": "l-B9RrIZDxPn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Let's see how our final model performs:**"
      ]
    },
    {
      "metadata": {
        "id": "iaHEdNqzYUBu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "outputId": "4fb8bca9-6d5c-46de-d1e0-46b70271d91e"
      },
      "cell_type": "code",
      "source": [
        "env = gym.make('BreakoutDeterministic-v4')\n",
        "agent = DQLAgent(cols, rows, n_actions = 3)\n",
        "\n",
        "for i in range(5):\n",
        "  observation = env.reset()\n",
        "  \n",
        "  state = preprocess_frame(observation).reshape(cols, rows)\n",
        "  history = np.stack((state, state, state, state), axis = 2)\n",
        "  history = np.reshape([history], (1, cols, rows, n_states))\n",
        "  \n",
        "  while not done:\n",
        "    # env.render()\n",
        "    action = agent.action(history)\n",
        "    observation, reward, done, info = env.step(action + 1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_13 (Conv2D)           (None, 20, 16, 32)        8224      \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 9, 7, 64)          32832     \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 7, 5, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 2240)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 512)               1147392   \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 3)                 1539      \n",
            "=================================================================\n",
            "Total params: 1,226,915\n",
            "Trainable params: 1,226,915\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_16 (Conv2D)           (None, 20, 16, 32)        8224      \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 9, 7, 64)          32832     \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 7, 5, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 2240)              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 512)               1147392   \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 3)                 1539      \n",
            "=================================================================\n",
            "Total params: 1,226,915\n",
            "Trainable params: 1,226,915\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}